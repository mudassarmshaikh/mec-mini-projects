{"cells":[{"cell_type":"markdown","source":["# Analyzing Web Server Logs with Apache Spark\n\nApache Spark is an excellent and ideal framework for wrangling, analyzing and modeling on structured and unstructured data - at scale! In this mini-project, we will be focusing on one of the most popular use-cases in the industry - log analytics.\n\nTypically, server logs are a very common data source in enterprises and often contain a gold mine of actionable insights and information. Log data comes from many sources in an enterprise, such as the web, client and compute servers, applications, user-generated content, flat files. They can be used for monitoring servers, improving business and customer intelligence, building recommendation systems, fraud detection, and much more.\n\nSpark allows you to dump and store your logs in files on disk cheaply, while still providing rich APIs to perform data analysis at scale. This mini-project will show you how to use Apache Spark on real-world production logs from NASA.\nYou will complete the extract, transform, and load (ETL) process in this Apache Spark enviroment. During this process, you will learn why the ETL process is so crucial to the quality of the machine learning work we will be doing later on.\n\n\nThere is a total of 15 questions for you to solve along with some interactive examples which will help you learn aspects of leveraging spark for analyzing over 3 million logs at scale.\n\nRemember to focus on the __`# TODO: Replace <FILL IN> with appropriate code`__ sections to fill them up with necessary code to solve the desired questions in the notebook"],"metadata":{"colab_type":"text","id":"q0ap-hmpXu-s","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c536fa6f-db7b-4364-b930-3fa9513b52f7"}}},{"cell_type":"markdown","source":["# Data extraction:"],"metadata":{"colab_type":"text","id":"6IkR5OAXYBVV","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9587c362-fe30-4006-9986-87f38999412d"}}},{"cell_type":"markdown","source":["# Step 1 - Loading up Dependencies"],"metadata":{"colab_type":"text","id":"W4XXOPlzXu-7","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9f9c60e9-973b-4cce-a758-d3d6ecae2fd0"}}},{"cell_type":"code","source":["spark"],"metadata":{"colab_type":"code","id":"zYGRL15uXu--","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4eb9a856-51c0-4155-99f6-6ddf2f55ba5b"},"colab":{},"outputId":"34c065c7-f451-4543-dde3-5ddbbcada8c6"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=71854493493941#setting/sparkui/1119-230855-uj917mkg/driver-8319955223272027521\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=71854493493941#setting/sparkui/1119-230855-uj917mkg/driver-8319955223272027521\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.2.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["sqlContext"],"metadata":{"colab_type":"code","id":"TQ9VOjOGXu_N","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"612d3da1-8e3a-47f6-93fa-09ced3604ff6"},"colab":{},"outputId":"8c2ee3dc-5d83-475e-c77a-3b83e98cff42"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[2]: <pyspark.sql.context.SQLContext at 0x7f53fdf7d7f0>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[2]: <pyspark.sql.context.SQLContext at 0x7f53fdf7d7f0>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["if 'sc' not in locals():\n    from pyspark.context import SparkContext\n    from pyspark.sql.context import SQLContext\n    from pyspark.sql.session import SparkSession\n    \n    sc = SparkContext()\n    sqlContext = SQLContext(sc)\n    spark = SparkSession(sc)"],"metadata":{"colab_type":"code","id":"IM6ajIMVXu_V","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"553e823b-1912-4951-9530-a8d806a7548e"},"colab":{},"outputId":"d49062e6-607c-42bf-e2de-5019dee77ce0"},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import re\nimport pandas as pd"],"metadata":{"colab_type":"code","id":"r3E2N5WCXu_b","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"078115ff-7447-4ec6-be1a-2cbbdf41ec4e"},"colab":{},"outputId":"cb9f5a8a-06b5-407a-c634-a703b3e5b92b"},"outputs":[],"execution_count":0},{"cell_type":"code","source":["m = re.finditer(r'.*?(spark).*?', \"I'm searching for a spark in PySpark\", re.I)\nfor match in m:\n    print(match)"],"metadata":{"colab_type":"code","id":"UupCPIruXu_i","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b27b59a7-693c-493d-b903-3c5bbcb4b8ad"},"colab":{},"outputId":"ae83b30e-9b7e-458f-fd16-94d9d738e589"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<re.Match object; span=(0, 25), match=\"I'm searching for a spark\">\n<re.Match object; span=(25, 36), match=' in PySpark'>\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["<re.Match object; span=(0, 25), match=\"I'm searching for a spark\">\n<re.Match object; span=(25, 36), match=' in PySpark'>\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["For this mini-project, we will analyze datasets from NASA Kennedy Space Center web server in Florida. The full data set is freely available for download [__here__](http://ita.ee.lbl.gov/html/contrib/NASA-HTTP.html).\n\nThese two traces contain two month's worth of all HTTP requests to the NASA Kennedy Space Center WWW server in Florida. You can head over to the [__website__](http://ita.ee.lbl.gov/html/contrib/NASA-HTTP.html) and download the following files if needed OR just upload the files we have already provided for you into Domino's Cloud Platform (unless you plan to use Spark locally).\n\n- Jul 01 to Jul 31, ASCII format, 20.7 MB gzip compressed, 205.2 MB uncompressed: [ftp://ita.ee.lbl.gov/traces/NASA_access_log_Jul95.gz](ftp://ita.ee.lbl.gov/traces/NASA_access_log_Jul95.gz)\n- Aug 04 to Aug 31, ASCII format, 21.8 MB gzip compressed, 167.8 MB uncompressed: [ftp://ita.ee.lbl.gov/traces/NASA_access_log_Aug95.gz](ftp://ita.ee.lbl.gov/traces/NASA_access_log_Aug95.gz)\n\nMake sure both the data files have been uploaded to Databricks under **\"Data\" > \"DBFS\" > \"Tables\"** as a **.txt** file\n\n\n![DBFS](https://drive.google.com/uc?id=1eE9_CgnUW7psBs_Nlk9qrdD2dXh1sU9A)"],"metadata":{"colab_type":"text","id":"Pln9za4iXu_n","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"01916dd0-b0e4-47d8-acf3-24eb16611cda"}}},{"cell_type":"markdown","source":["# Step 2 - Loading and Viewing the Log Dataset\n\nGiven that our data is stored in the following mentioned path, let's load it into a DataFrame. We'll do this in steps. First, we'll use `sqlContext.read.text()` or `spark.read.text()` to read the text file. This will produce a DataFrame with a single string column called `value`."],"metadata":{"colab_type":"text","id":"KESqVXmAXu_p","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cfe0cd59-b1d2-4c11-9d03-1dfebbc2d9a7"}}},{"cell_type":"markdown","source":["### Taking a look at the metadata of our dataframe"],"metadata":{"colab_type":"text","id":"pis2_lWcXu_u","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d843dd27-11cc-483d-8d76-a06974dea294"}}},{"cell_type":"code","source":["# make sure you have upload NASA_access_log_Aug95.txt and NASA_access_log_Jul95.txt onto Spark before you run the following code\n\nbase_df = spark.read.text('dbfs:/FileStore/tables/*95.gz')\nbase_df.printSchema()"],"metadata":{"colab_type":"code","id":"f4-znXsmXu_w","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c01075d2-7842-46cd-94f8-63ec95868f65"},"colab":{},"outputId":"5c326d84-2124-47c4-c63f-e70665bfb820"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- value: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- value: string (nullable = true)\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["type(base_df)"],"metadata":{"colab_type":"code","id":"IBHQ8QQkXu_0","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a909de32-1569-43cb-8265-df11e64fd1ad"},"colab":{},"outputId":"14c57eda-586c-4a28-9e1c-df9364bf0ff8"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[7]: pyspark.sql.dataframe.DataFrame","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[7]: pyspark.sql.dataframe.DataFrame"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["You can also convert a dataframe to an RDD if needed"],"metadata":{"colab_type":"text","id":"gOKkUBQvXu_5","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"64b99423-f1ed-4bf4-9ad0-8e3b0f2a1506"}}},{"cell_type":"code","source":["base_df_rdd = base_df.rdd\ntype(base_df_rdd)"],"metadata":{"colab_type":"code","id":"hMByB80sXu_6","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"13978c7f-d6ca-4824-a0c1-30e05e94b61e"},"colab":{},"outputId":"29f8e5c6-aecf-4f81-d1e8-40a5ef92eb18"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[8]: pyspark.rdd.RDD","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[8]: pyspark.rdd.RDD"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Viewing sample data in our dataframe\nLooks like it needs to be wrangled and parsed!"],"metadata":{"colab_type":"text","id":"oi1QtXBhXvAB","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a4336f7b-c809-492c-a9e0-36923ed07905"}}},{"cell_type":"code","source":["base_df.show(10, truncate=False)"],"metadata":{"colab_type":"code","id":"iertYldRXvAD","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca5afbb9-d704-432d-ba54-ad9e1cea74ca"},"colab":{},"outputId":"cf7a1843-1287-455e-a32c-e67a498a89c0"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----------------------------------------------------------------------------------------------------------------------+\n|value                                                                                                                  |\n+-----------------------------------------------------------------------------------------------------------------------+\n|199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245                                 |\n|unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985                      |\n|199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085   |\n|burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0               |\n|199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179|\n|burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0                    |\n|burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/video/livevideo.gif HTTP/1.0\" 200 0        |\n|205.212.115.106 - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/countdown.html HTTP/1.0\" 200 3985             |\n|d104.aa.net - - [01/Jul/1995:00:00:13 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985                               |\n|129.94.144.152 - - [01/Jul/1995:00:00:13 -0400] \"GET / HTTP/1.0\" 200 7074                                              |\n+-----------------------------------------------------------------------------------------------------------------------+\nonly showing top 10 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------------------------------------------------------------------------------------------------------------------+\n|value                                                                                                                  |\n+-----------------------------------------------------------------------------------------------------------------------+\n|199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245                                 |\n|unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985                      |\n|199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085   |\n|burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0               |\n|199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179|\n|burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0                    |\n|burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/video/livevideo.gif HTTP/1.0\" 200 0        |\n|205.212.115.106 - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/countdown.html HTTP/1.0\" 200 3985             |\n|d104.aa.net - - [01/Jul/1995:00:00:13 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985                               |\n|129.94.144.152 - - [01/Jul/1995:00:00:13 -0400] \"GET / HTTP/1.0\" 200 7074                                              |\n+-----------------------------------------------------------------------------------------------------------------------+\nonly showing top 10 rows\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["Getting data from an RDD is slightly different. You can see how the data representation is different in the following RDD"],"metadata":{"colab_type":"text","id":"T9aeiekzXvAJ","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d916d6d0-d2ce-4583-9821-04ace62bbee9"}}},{"cell_type":"code","source":["base_df_rdd.take(10)"],"metadata":{"colab_type":"code","id":"PCdKKlCeXvAK","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c33c7c45-9746-4aa8-9dd0-87d9f4f38f18"},"colab":{},"outputId":"58876be0-2960-4df1-cefa-75daa1462dbd"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[10]: [Row(value='199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245'),\n Row(value='unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985'),\n Row(value='199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085'),\n Row(value='burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0'),\n Row(value='199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179'),\n Row(value='burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0'),\n Row(value='burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/video/livevideo.gif HTTP/1.0\" 200 0'),\n Row(value='205.212.115.106 - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/countdown.html HTTP/1.0\" 200 3985'),\n Row(value='d104.aa.net - - [01/Jul/1995:00:00:13 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985'),\n Row(value='129.94.144.152 - - [01/Jul/1995:00:00:13 -0400] \"GET / HTTP/1.0\" 200 7074')]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[10]: [Row(value='199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245'),\n Row(value='unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985'),\n Row(value='199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085'),\n Row(value='burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0'),\n Row(value='199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179'),\n Row(value='burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0'),\n Row(value='burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/video/livevideo.gif HTTP/1.0\" 200 0'),\n Row(value='205.212.115.106 - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/countdown.html HTTP/1.0\" 200 3985'),\n Row(value='d104.aa.net - - [01/Jul/1995:00:00:13 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985'),\n Row(value='129.94.144.152 - - [01/Jul/1995:00:00:13 -0400] \"GET / HTTP/1.0\" 200 7074')]"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["# Data transformation"],"metadata":{"colab_type":"text","id":"asaanbGIYfR8","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7d99a72-aa21-4ea2-9347-c68b845ca9b1"}}},{"cell_type":"markdown","source":["# Step 1 - Data Wrangling\n\nIn this section, we will try and clean and parse our log dataset to really extract structured attributes with meaningful information from each log message.\n\n### Data understanding\nIf you're familiar with web server logs, you'll recognize that the above displayed data is in [Common Log Format](https://www.w3.org/Daemon/User/Config/Logging.html#common-logfile-format). \n\nThe fields are:\n__`remotehost rfc931 authuser [date] \"request\" status bytes`__\n\n\n| field         | meaning                                                                |\n| ------------- | ---------------------------------------------------------------------- |\n| _remotehost_  | Remote hostname (or IP number if DNS hostname is not available or if [DNSLookup](https://www.w3.org/Daemon/User/Config/General.html#DNSLookup) is off).       |\n| _rfc931_      | The remote logname of the user if at all it is present. |\n| _authuser_    | The username of the remote user after authentication by the HTTP server.  |\n| _[date]_      | Date and time of the request.                                      |\n| _\"request\"_   | The request, exactly as it came from the browser or client.            |\n| _status_      | The [HTTP status code](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes) the server sent back to the client.               |\n| _bytes_       | The number of bytes (`Content-Length`) transferred to the client.      |\n\nWe will need to use some specific techniques to parse, match and extract these attributes from the log data"],"metadata":{"colab_type":"text","id":"yv5kCt3xXvAP","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0648c5cd-e8e9-4823-89c1-2732fdd516c1"}}},{"cell_type":"markdown","source":["## Data Parsing and Extraction with Regular Expressions\n\nNext, we have to parse it into individual columns. We'll use the special built-in [regexp\\_extract()](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.regexp_extract)\nfunction to do the parsing. This function matches a column against a regular expression with one or more [capture groups](http://regexone.com/lesson/capturing_groups) and allows you to extract one of the matched groups. We'll use one regular expression for each field we wish to extract.\n\nYou must have heard or used a fair bit of regular expressions by now. If you find regular expressions confusing (and they certainly _can_ be), and you want to learn more about them, we recommend checking out the\n[RegexOne web site](http://regexone.com/). You might also find [_Regular Expressions Cookbook_](http://shop.oreilly.com/product/0636920023630.do), by Goyvaerts and Levithan, to be useful as a reference."],"metadata":{"colab_type":"text","id":"9aCEcwBLXvAQ","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9095e279-b6da-421f-85d4-2440b8d5784a"}}},{"cell_type":"markdown","source":["#### Let's take a look at our dataset dimensions"],"metadata":{"colab_type":"text","id":"a3TFNjb1XvAS","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ecad8a43-dc28-43fc-847f-13aaad8c4827"}}},{"cell_type":"code","source":["print((base_df.count(), len(base_df.columns)))\n"],"metadata":{"colab_type":"code","id":"ncbKGPMJXvAT","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9d126431-d058-41d3-a01a-b4e618684b66"},"colab":{},"outputId":"2d0a17f7-5bd7-444a-9a65-f547bf601f09"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"(3461613, 1)\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["(3461613, 1)\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["Let's extract and take a look at some sample log messages"],"metadata":{"colab_type":"text","id":"dtZOfHsVXvAZ","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9ce8fae8-0b42-42c0-87f3-e4247ac4dd3e"}}},{"cell_type":"code","source":["sample_logs = [item['value'] for item in base_df.take(15)]\nsample_logs"],"metadata":{"colab_type":"code","id":"-3sfUy4NXvAa","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a8c6d170-a251-4103-a474-e0f8e403ee8f"},"colab":{},"outputId":"056e2311-d4be-4c1b-e507-a4c6f1868ace"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[12]: ['199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245',\n 'unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985',\n '199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085',\n 'burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0',\n '199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179',\n 'burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0',\n 'burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/video/livevideo.gif HTTP/1.0\" 200 0',\n '205.212.115.106 - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/countdown.html HTTP/1.0\" 200 3985',\n 'd104.aa.net - - [01/Jul/1995:00:00:13 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985',\n '129.94.144.152 - - [01/Jul/1995:00:00:13 -0400] \"GET / HTTP/1.0\" 200 7074',\n 'unicomp6.unicomp.net - - [01/Jul/1995:00:00:14 -0400] \"GET /shuttle/countdown/count.gif HTTP/1.0\" 200 40310',\n 'unicomp6.unicomp.net - - [01/Jul/1995:00:00:14 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786',\n 'unicomp6.unicomp.net - - [01/Jul/1995:00:00:14 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 200 1204',\n 'd104.aa.net - - [01/Jul/1995:00:00:15 -0400] \"GET /shuttle/countdown/count.gif HTTP/1.0\" 200 40310',\n 'd104.aa.net - - [01/Jul/1995:00:00:15 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786']","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[12]: ['199.72.81.55 - - [01/Jul/1995:00:00:01 -0400] \"GET /history/apollo/ HTTP/1.0\" 200 6245',\n 'unicomp6.unicomp.net - - [01/Jul/1995:00:00:06 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985',\n '199.120.110.21 - - [01/Jul/1995:00:00:09 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4085',\n 'burger.letters.com - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/countdown/liftoff.html HTTP/1.0\" 304 0',\n '199.120.110.21 - - [01/Jul/1995:00:00:11 -0400] \"GET /shuttle/missions/sts-73/sts-73-patch-small.gif HTTP/1.0\" 200 4179',\n 'burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 304 0',\n 'burger.letters.com - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/video/livevideo.gif HTTP/1.0\" 200 0',\n '205.212.115.106 - - [01/Jul/1995:00:00:12 -0400] \"GET /shuttle/countdown/countdown.html HTTP/1.0\" 200 3985',\n 'd104.aa.net - - [01/Jul/1995:00:00:13 -0400] \"GET /shuttle/countdown/ HTTP/1.0\" 200 3985',\n '129.94.144.152 - - [01/Jul/1995:00:00:13 -0400] \"GET / HTTP/1.0\" 200 7074',\n 'unicomp6.unicomp.net - - [01/Jul/1995:00:00:14 -0400] \"GET /shuttle/countdown/count.gif HTTP/1.0\" 200 40310',\n 'unicomp6.unicomp.net - - [01/Jul/1995:00:00:14 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786',\n 'unicomp6.unicomp.net - - [01/Jul/1995:00:00:14 -0400] \"GET /images/KSC-logosmall.gif HTTP/1.0\" 200 1204',\n 'd104.aa.net - - [01/Jul/1995:00:00:15 -0400] \"GET /shuttle/countdown/count.gif HTTP/1.0\" 200 40310',\n 'd104.aa.net - - [01/Jul/1995:00:00:15 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786']"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"04d8cc0a-7139-4154-aeff-88486fa25143"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Extracting host names\n\nLet's try and write some regular expressions to extract the host name from the logs"],"metadata":{"colab_type":"text","id":"0aPYBjkwXvAf","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"00d4b67f-c434-4190-b971-3a85f23b6730"}}},{"cell_type":"code","source":["host_pattern = r'(^\\S+\\.[\\S+\\.]+\\S+)\\s'\nhosts = [re.search(host_pattern, item).group(1)\n           if re.search(host_pattern, item)\n           else 'no match'\n           for item in sample_logs]\nhosts"],"metadata":{"colab_type":"code","id":"WarNo8bGXvAh","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"49cc0b7e-6723-40ca-b342-dbd93c972d0a"},"colab":{},"outputId":"d8a548f2-335e-4ab4-8a9f-28f55060e540"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[13]: ['199.72.81.55',\n 'unicomp6.unicomp.net',\n '199.120.110.21',\n 'burger.letters.com',\n '199.120.110.21',\n 'burger.letters.com',\n 'burger.letters.com',\n '205.212.115.106',\n 'd104.aa.net',\n '129.94.144.152',\n 'unicomp6.unicomp.net',\n 'unicomp6.unicomp.net',\n 'unicomp6.unicomp.net',\n 'd104.aa.net',\n 'd104.aa.net']","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[13]: ['199.72.81.55',\n 'unicomp6.unicomp.net',\n '199.120.110.21',\n 'burger.letters.com',\n '199.120.110.21',\n 'burger.letters.com',\n 'burger.letters.com',\n '205.212.115.106',\n 'd104.aa.net',\n '129.94.144.152',\n 'unicomp6.unicomp.net',\n 'unicomp6.unicomp.net',\n 'unicomp6.unicomp.net',\n 'd104.aa.net',\n 'd104.aa.net']"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Extracting timestamps \n\nLet's now try and use regular expressions to extract the timestamp fields from the logs"],"metadata":{"colab_type":"text","id":"TcZrGpgwXvAk","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d50e63e9-4f81-427e-91fa-9e9407ef6d0d"}}},{"cell_type":"code","source":["ts_pattern = r'\\[(\\d{2}/\\w{3}/\\d{4}:\\d{2}:\\d{2}:\\d{2} -\\d{4})]'\ntimestamps = [re.search(ts_pattern, item).group(1) for item in sample_logs]\ntimestamps"],"metadata":{"colab_type":"code","id":"GOot8niKXvAl","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"da590d17-1946-46d1-8842-bf6530bc82e6"},"colab":{},"outputId":"6ad3338e-8ff0-48f1-c4d0-ad52742232b9"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[14]: ['01/Jul/1995:00:00:01 -0400',\n '01/Jul/1995:00:00:06 -0400',\n '01/Jul/1995:00:00:09 -0400',\n '01/Jul/1995:00:00:11 -0400',\n '01/Jul/1995:00:00:11 -0400',\n '01/Jul/1995:00:00:12 -0400',\n '01/Jul/1995:00:00:12 -0400',\n '01/Jul/1995:00:00:12 -0400',\n '01/Jul/1995:00:00:13 -0400',\n '01/Jul/1995:00:00:13 -0400',\n '01/Jul/1995:00:00:14 -0400',\n '01/Jul/1995:00:00:14 -0400',\n '01/Jul/1995:00:00:14 -0400',\n '01/Jul/1995:00:00:15 -0400',\n '01/Jul/1995:00:00:15 -0400']","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[14]: ['01/Jul/1995:00:00:01 -0400',\n '01/Jul/1995:00:00:06 -0400',\n '01/Jul/1995:00:00:09 -0400',\n '01/Jul/1995:00:00:11 -0400',\n '01/Jul/1995:00:00:11 -0400',\n '01/Jul/1995:00:00:12 -0400',\n '01/Jul/1995:00:00:12 -0400',\n '01/Jul/1995:00:00:12 -0400',\n '01/Jul/1995:00:00:13 -0400',\n '01/Jul/1995:00:00:13 -0400',\n '01/Jul/1995:00:00:14 -0400',\n '01/Jul/1995:00:00:14 -0400',\n '01/Jul/1995:00:00:14 -0400',\n '01/Jul/1995:00:00:15 -0400',\n '01/Jul/1995:00:00:15 -0400']"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Extracting HTTP Request Method, URIs and Protocol \n\nLet's now try and use regular expressions to extract the HTTP request methods, URIs and Protocol patterns fields from the logs"],"metadata":{"colab_type":"text","id":"CKJ5F8tCXvAo","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"89365239-29b5-4cc3-a659-ac00ff6d5944"}}},{"cell_type":"code","source":["method_uri_protocol_pattern = r'\\\"(\\S+)\\s(\\S+)\\s*(\\S*)\\\"'\nmethod_uri_protocol = [re.search(method_uri_protocol_pattern, item).groups()\n               if re.search(method_uri_protocol_pattern, item)\n               else 'no match'\n              for item in sample_logs]\nmethod_uri_protocol"],"metadata":{"colab_type":"code","id":"TZvnPVXeXvAp","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fdd5fb49-99d6-426e-9d58-d8a131ac271a"},"colab":{},"outputId":"f3cdd71d-0239-43a4-fd8f-245193f571c3"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[15]: [('GET', '/history/apollo/', 'HTTP/1.0'),\n ('GET', '/shuttle/countdown/', 'HTTP/1.0'),\n ('GET', '/shuttle/missions/sts-73/mission-sts-73.html', 'HTTP/1.0'),\n ('GET', '/shuttle/countdown/liftoff.html', 'HTTP/1.0'),\n ('GET', '/shuttle/missions/sts-73/sts-73-patch-small.gif', 'HTTP/1.0'),\n ('GET', '/images/NASA-logosmall.gif', 'HTTP/1.0'),\n ('GET', '/shuttle/countdown/video/livevideo.gif', 'HTTP/1.0'),\n ('GET', '/shuttle/countdown/countdown.html', 'HTTP/1.0'),\n ('GET', '/shuttle/countdown/', 'HTTP/1.0'),\n ('GET', '/', 'HTTP/1.0'),\n ('GET', '/shuttle/countdown/count.gif', 'HTTP/1.0'),\n ('GET', '/images/NASA-logosmall.gif', 'HTTP/1.0'),\n ('GET', '/images/KSC-logosmall.gif', 'HTTP/1.0'),\n ('GET', '/shuttle/countdown/count.gif', 'HTTP/1.0'),\n ('GET', '/images/NASA-logosmall.gif', 'HTTP/1.0')]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[15]: [('GET', '/history/apollo/', 'HTTP/1.0'),\n ('GET', '/shuttle/countdown/', 'HTTP/1.0'),\n ('GET', '/shuttle/missions/sts-73/mission-sts-73.html', 'HTTP/1.0'),\n ('GET', '/shuttle/countdown/liftoff.html', 'HTTP/1.0'),\n ('GET', '/shuttle/missions/sts-73/sts-73-patch-small.gif', 'HTTP/1.0'),\n ('GET', '/images/NASA-logosmall.gif', 'HTTP/1.0'),\n ('GET', '/shuttle/countdown/video/livevideo.gif', 'HTTP/1.0'),\n ('GET', '/shuttle/countdown/countdown.html', 'HTTP/1.0'),\n ('GET', '/shuttle/countdown/', 'HTTP/1.0'),\n ('GET', '/', 'HTTP/1.0'),\n ('GET', '/shuttle/countdown/count.gif', 'HTTP/1.0'),\n ('GET', '/images/NASA-logosmall.gif', 'HTTP/1.0'),\n ('GET', '/images/KSC-logosmall.gif', 'HTTP/1.0'),\n ('GET', '/shuttle/countdown/count.gif', 'HTTP/1.0'),\n ('GET', '/images/NASA-logosmall.gif', 'HTTP/1.0')]"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Building an intermediate parsed dataframe\n\nLet's try and use our regular expressions we have implemented so far into parsing and extracting the relevant entities in separate columns in a new dataframe"],"metadata":{"colab_type":"text","id":"oaBizluJXvAu","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ad3cfb7-1f91-4980-94fd-b7ba035f8a4c"}}},{"cell_type":"code","source":["from pyspark.sql.functions import regexp_extract\n\nlogs_df = base_df.select(regexp_extract('value', host_pattern, 1).alias('host'),\n                         regexp_extract('value', ts_pattern, 1).alias('timestamp'),\n                         regexp_extract('value', method_uri_protocol_pattern, 1).alias('method'),\n                         regexp_extract('value', method_uri_protocol_pattern, 2).alias('endpoint'),\n                         regexp_extract('value', method_uri_protocol_pattern, 3).alias('protocol'))\nlogs_df.show(10, truncate=False)\nprint((logs_df.count(), len(logs_df.columns)))"],"metadata":{"colab_type":"code","id":"MLI8LUVPXvAv","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7ca9b70-1246-4a3c-93c3-950aa3fafdbb"},"colab":{},"outputId":"5c8becac-e3bb-4a61-cc8e-bba69c4169d6"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+--------------------------+------+-----------------------------------------------+--------+\n|host                |timestamp                 |method|endpoint                                       |protocol|\n+--------------------+--------------------------+------+-----------------------------------------------+--------+\n|199.72.81.55        |01/Jul/1995:00:00:01 -0400|GET   |/history/apollo/                               |HTTP/1.0|\n|unicomp6.unicomp.net|01/Jul/1995:00:00:06 -0400|GET   |/shuttle/countdown/                            |HTTP/1.0|\n|199.120.110.21      |01/Jul/1995:00:00:09 -0400|GET   |/shuttle/missions/sts-73/mission-sts-73.html   |HTTP/1.0|\n|burger.letters.com  |01/Jul/1995:00:00:11 -0400|GET   |/shuttle/countdown/liftoff.html                |HTTP/1.0|\n|199.120.110.21      |01/Jul/1995:00:00:11 -0400|GET   |/shuttle/missions/sts-73/sts-73-patch-small.gif|HTTP/1.0|\n|burger.letters.com  |01/Jul/1995:00:00:12 -0400|GET   |/images/NASA-logosmall.gif                     |HTTP/1.0|\n|burger.letters.com  |01/Jul/1995:00:00:12 -0400|GET   |/shuttle/countdown/video/livevideo.gif         |HTTP/1.0|\n|205.212.115.106     |01/Jul/1995:00:00:12 -0400|GET   |/shuttle/countdown/countdown.html              |HTTP/1.0|\n|d104.aa.net         |01/Jul/1995:00:00:13 -0400|GET   |/shuttle/countdown/                            |HTTP/1.0|\n|129.94.144.152      |01/Jul/1995:00:00:13 -0400|GET   |/                                              |HTTP/1.0|\n+--------------------+--------------------------+------+-----------------------------------------------+--------+\nonly showing top 10 rows\n\n(3461613, 5)\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+--------------------------+------+-----------------------------------------------+--------+\n|host                |timestamp                 |method|endpoint                                       |protocol|\n+--------------------+--------------------------+------+-----------------------------------------------+--------+\n|199.72.81.55        |01/Jul/1995:00:00:01 -0400|GET   |/history/apollo/                               |HTTP/1.0|\n|unicomp6.unicomp.net|01/Jul/1995:00:00:06 -0400|GET   |/shuttle/countdown/                            |HTTP/1.0|\n|199.120.110.21      |01/Jul/1995:00:00:09 -0400|GET   |/shuttle/missions/sts-73/mission-sts-73.html   |HTTP/1.0|\n|burger.letters.com  |01/Jul/1995:00:00:11 -0400|GET   |/shuttle/countdown/liftoff.html                |HTTP/1.0|\n|199.120.110.21      |01/Jul/1995:00:00:11 -0400|GET   |/shuttle/missions/sts-73/sts-73-patch-small.gif|HTTP/1.0|\n|burger.letters.com  |01/Jul/1995:00:00:12 -0400|GET   |/images/NASA-logosmall.gif                     |HTTP/1.0|\n|burger.letters.com  |01/Jul/1995:00:00:12 -0400|GET   |/shuttle/countdown/video/livevideo.gif         |HTTP/1.0|\n|205.212.115.106     |01/Jul/1995:00:00:12 -0400|GET   |/shuttle/countdown/countdown.html              |HTTP/1.0|\n|d104.aa.net         |01/Jul/1995:00:00:13 -0400|GET   |/shuttle/countdown/                            |HTTP/1.0|\n|129.94.144.152      |01/Jul/1995:00:00:13 -0400|GET   |/                                              |HTTP/1.0|\n+--------------------+--------------------------+------+-----------------------------------------------+--------+\nonly showing top 10 rows\n\n(3461613, 5)\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Extracting HTTP Status Codes\n\nLet's now try and use regular expressions to extract the HTTP status codes from the logs"],"metadata":{"colab_type":"text","id":"-c-LK4TNXvAy","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"68aa112b-a5d8-45af-9d71-059de3ce9a2f"}}},{"cell_type":"code","source":["status_pattern = r'\\s(\\d{3})\\s'\nstatus = [re.search(status_pattern, item).group(1) for item in sample_logs]\nprint(status)"],"metadata":{"colab_type":"code","id":"kvWWXeTcXvA1","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2596548a-0256-4d49-88c5-f4383e74aab8"},"colab":{},"outputId":"5ffeabc8-ecff-4365-af5f-0b905f913115"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"['200', '200', '200', '304', '200', '304', '200', '200', '200', '200', '200', '200', '200', '200', '200']\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["['200', '200', '200', '304', '200', '304', '200', '200', '200', '200', '200', '200', '200', '200', '200']\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f4cec6c0-5a1c-42c6-a95f-45649f40215c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Extracting HTTP Response Content Size\n\nLet's now try and use regular expressions to extract the HTTP response content size from the logs"],"metadata":{"colab_type":"text","id":"jFemwBnSXvA4","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e621dc74-d971-48b4-87dd-b52fcc95841a"}}},{"cell_type":"code","source":["content_size_pattern = r'\\s(\\d+)$'\ncontent_size = [re.search(content_size_pattern, item).group(1) for item in sample_logs]\nprint(content_size)"],"metadata":{"colab_type":"code","id":"l0kmQOqjXvA5","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"589f8bb6-81e1-4421-bc3c-aae798ee463f"},"colab":{},"outputId":"8b6c6d90-6897-4885-e527-0b815f4a977e"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"['6245', '3985', '4085', '0', '4179', '0', '0', '3985', '3985', '7074', '40310', '786', '1204', '40310', '786']\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["['6245', '3985', '4085', '0', '4179', '0', '0', '3985', '3985', '7074', '40310', '786', '1204', '40310', '786']\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8e7cc73a-4bcc-4512-acb8-1ac3b9b4bb91"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Q1: Your Turn: Putting it all together \n\nLet's now try and leverage all the regular expression patterns we previously built and use the `regexp_extract(...)` method to build our dataframe with all the log attributes neatly extracted in their own separate columns.\n\n- You can reuse the code we used previously to build the intermediate dataframe\n- Remember to cast the HTTP status code and content size as integers. \n- You can cast data as integer type using the following: __`regexp_extract('value', ...., ...).cast('integer').alias(...)`__"],"metadata":{"colab_type":"text","id":"DHPbsgMsXvA8","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0ee66911-dfde-4593-a815-1443ddeef963"}}},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\n\nlogs_df = base_df.select(regexp_extract('value', host_pattern, 1).alias('host'),\n                         regexp_extract('value', ts_pattern, 1).alias('timestamp'),\n                         regexp_extract('value', method_uri_protocol_pattern, 1).alias('method'),\n                         regexp_extract('value', method_uri_protocol_pattern, 2).alias('endpoint'),\n                         regexp_extract('value', method_uri_protocol_pattern, 3).alias('protocol'),\n                         regexp_extract('value', status_pattern, 1).alias('status'),\n                         regexp_extract('value', content_size_pattern, 1).alias('content_size'))\nlogs_df.show(10, truncate=True)\nprint((logs_df.count(), len(logs_df.columns)))"],"metadata":{"colab_type":"code","id":"bM4iBWjRXvA-","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5299f588-ecf2-4434-9102-3e83088abf08"},"colab":{},"outputId":"b826a364-3709-4c6f-eb67-541e08c535ac"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+--------------------+------+--------------------+--------+------+------------+\n|                host|           timestamp|method|            endpoint|protocol|status|content_size|\n+--------------------+--------------------+------+--------------------+--------+------+------------+\n|        199.72.81.55|01/Jul/1995:00:00...|   GET|    /history/apollo/|HTTP/1.0|   200|        6245|\n|unicomp6.unicomp.net|01/Jul/1995:00:00...|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|\n|      199.120.110.21|01/Jul/1995:00:00...|   GET|/shuttle/missions...|HTTP/1.0|   200|        4085|\n|  burger.letters.com|01/Jul/1995:00:00...|   GET|/shuttle/countdow...|HTTP/1.0|   304|           0|\n|      199.120.110.21|01/Jul/1995:00:00...|   GET|/shuttle/missions...|HTTP/1.0|   200|        4179|\n|  burger.letters.com|01/Jul/1995:00:00...|   GET|/images/NASA-logo...|HTTP/1.0|   304|           0|\n|  burger.letters.com|01/Jul/1995:00:00...|   GET|/shuttle/countdow...|HTTP/1.0|   200|           0|\n|     205.212.115.106|01/Jul/1995:00:00...|   GET|/shuttle/countdow...|HTTP/1.0|   200|        3985|\n|         d104.aa.net|01/Jul/1995:00:00...|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|\n|      129.94.144.152|01/Jul/1995:00:00...|   GET|                   /|HTTP/1.0|   200|        7074|\n+--------------------+--------------------+------+--------------------+--------+------+------------+\nonly showing top 10 rows\n\n(3461613, 7)\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+--------------------+------+--------------------+--------+------+------------+\n|                host|           timestamp|method|            endpoint|protocol|status|content_size|\n+--------------------+--------------------+------+--------------------+--------+------+------------+\n|        199.72.81.55|01/Jul/1995:00:00...|   GET|    /history/apollo/|HTTP/1.0|   200|        6245|\n|unicomp6.unicomp.net|01/Jul/1995:00:00...|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|\n|      199.120.110.21|01/Jul/1995:00:00...|   GET|/shuttle/missions...|HTTP/1.0|   200|        4085|\n|  burger.letters.com|01/Jul/1995:00:00...|   GET|/shuttle/countdow...|HTTP/1.0|   304|           0|\n|      199.120.110.21|01/Jul/1995:00:00...|   GET|/shuttle/missions...|HTTP/1.0|   200|        4179|\n|  burger.letters.com|01/Jul/1995:00:00...|   GET|/images/NASA-logo...|HTTP/1.0|   304|           0|\n|  burger.letters.com|01/Jul/1995:00:00...|   GET|/shuttle/countdow...|HTTP/1.0|   200|           0|\n|     205.212.115.106|01/Jul/1995:00:00...|   GET|/shuttle/countdow...|HTTP/1.0|   200|        3985|\n|         d104.aa.net|01/Jul/1995:00:00...|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|\n|      129.94.144.152|01/Jul/1995:00:00...|   GET|                   /|HTTP/1.0|   200|        7074|\n+--------------------+--------------------+------+--------------------+--------+------+------------+\nonly showing top 10 rows\n\n(3461613, 7)\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Finding Missing Values\n\nMissing and null values are the bane of data analysis and machine learning. Let's see how well our data parsing and extraction logic worked. First, let's verify that there are no null rows in the original dataframe."],"metadata":{"colab_type":"text","id":"EgLGxYRYXvBB","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"400f3712-4935-4e53-bf5d-577878e3b8d4"}}},{"cell_type":"code","source":["base_df.filter(base_df['value'].isNull()).count()"],"metadata":{"colab_type":"code","id":"O4ppVUoJXvBC","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"52d9cd3b-b1e1-4815-8c30-ac220c4b8d1e"},"colab":{},"outputId":"18c683c1-5f0d-4f62-9545-e9bd27088c80"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[20]: 0","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[20]: 0"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["If our data parsing and extraction worked properly, we should not have any rows with potential null values. Let's try and put that to test!"],"metadata":{"colab_type":"text","id":"7V0g6vHcXvBG","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e9b26b43-6635-4bef-bcad-61f3c4b8266e"}}},{"cell_type":"code","source":["bad_rows_df = logs_df.filter(logs_df['host'].isNull()| \n                             logs_df['timestamp'].isNull() | \n                             logs_df['method'].isNull() |\n                             logs_df['endpoint'].isNull() |\n                             logs_df['status'].isNull() |\n                             logs_df['content_size'].isNull()|\n                             logs_df['protocol'].isNull())\nbad_rows_df.count()"],"metadata":{"colab_type":"code","id":"4NFuk6QTXvBH","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c947d783-a7de-463e-8f45-936d979f8ca4"},"colab":{},"outputId":"a8238a74-51c8-48ac-fe83-b67f42d0a78c"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[21]: 0","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[21]: 0"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["Ouch! Looks like we have over 30K missing values in our data! Can we handle this?"],"metadata":{"colab_type":"text","id":"CIqr5XvhXvBM","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2a0d0100-5ebc-4d35-9fa8-570c6161f0f8"}}},{"cell_type":"markdown","source":["Do remember, this is not a regular pandas dataframe which you can directly query and get which columns have null. Our so-called _big dataset_ is residing on disk which can potentially be present in multiple nodes in a spark cluster. So how do we find out which columns have potential nulls? \n\n### Finding Null Counts\n\nWe can typically use the following technique to find out which columns have null values. \n\n(__Note:__ This approach is adapted from an [excellent answer](http://stackoverflow.com/a/33901312) on StackOverflow.)"],"metadata":{"colab_type":"text","id":"g8iWYrBoXvBN","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3d32fc2b-caf0-491e-83ea-55edf8b0ba02"}}},{"cell_type":"code","source":["logs_df.columns"],"metadata":{"colab_type":"code","id":"h0TWdnaPXvBP","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2a716a80-8c11-45b6-9bd6-8005bd4a43a1"},"colab":{},"outputId":"8a7abfda-2629-4f36-cb9c-3e00a13efa83"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[22]: ['host',\n 'timestamp',\n 'method',\n 'endpoint',\n 'protocol',\n 'status',\n 'content_size']","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[22]: ['host',\n 'timestamp',\n 'method',\n 'endpoint',\n 'protocol',\n 'status',\n 'content_size']"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2a098716-8db7-4dda-b34e-e918b1160cba"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7cc9cf99-83c2-4ffc-b338-16b560c1c3ef"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import col\nfrom pyspark.sql.functions import sum as spark_sum\n\ndef count_null(col_name):\n    return spark_sum(col(col_name).isNull().cast('integer')).alias(col_name)\n\n# Build up a list of column expressions, one per column.\nexprs = [count_null(col_name) for col_name in logs_df.columns]\n\n# Run the aggregation. The *exprs converts the list of expressions into\n# variable function arguments.\nlogs_df.agg(*exprs).show()"],"metadata":{"colab_type":"code","id":"LtNLdagZXvBT","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dc157d07-58dd-44d0-a9e6-7cb3d395c03c"},"colab":{},"outputId":"e9fba1ca-d183-4728-9f7c-135ebcd78ec9"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----+---------+------+--------+--------+------+------------+\n|host|timestamp|method|endpoint|protocol|status|content_size|\n+----+---------+------+--------+--------+------+------------+\n|   0|        0|     0|       0|       0|     0|           0|\n+----+---------+------+--------+--------+------+------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+---------+------+--------+--------+------+------------+\n|host|timestamp|method|endpoint|protocol|status|content_size|\n+----+---------+------+--------+--------+------+------------+\n|   0|        0|     0|       0|       0|     0|           0|\n+----+---------+------+--------+--------+------+------------+\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6245ceae-67ae-426e-a9a6-f1e8c63919e7"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Well, looks like we have one missing value in the `status` column and everything else is in the `content_size` column. \nLet's see if we can figure out what's wrong!"],"metadata":{"colab_type":"text","id":"g5z_B22MXvBX","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e6e1c0ad-228e-44b1-ad55-75ad3a3434ac"}}},{"cell_type":"markdown","source":["### Handling nulls in HTTP status\n\nIf you had solved it correctly, our original parsing regular expression for the `status` column was:\n\n```\nregexp_extract('value', r'\\s(\\d{3})\\s', 1).cast('integer').alias('status')\n``` \n\nCould it be that there are more digits making our regular expression wrong? or is the data point itself bad? Let's try and find out!\n\n**Note**: In the expression below, `~` means \"not\"."],"metadata":{"colab_type":"text","id":"jGoLzGeEXvBZ","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"00efbbe1-eb83-4420-a1a1-c9bc75c9c114"}}},{"cell_type":"code","source":["null_status_df = base_df.filter(~base_df['value'].rlike(r'\\s(\\d{3})\\s'))\nnull_status_df.count()"],"metadata":{"colab_type":"code","id":"tscbB01GXvBb","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4eaecbc4-2f2c-40f0-8bea-91e3e3fbd3e2"},"colab":{},"outputId":"97996e0a-5e21-441f-b742-3e898e691c43"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[24]: 1","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[24]: 1"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3a3b8bf1-fe55-4c6d-bf4b-49b4155c6a66"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["null_status_df.show(truncate=False)"],"metadata":{"colab_type":"code","id":"KMRiPoTXXvBe","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5e78079c-5397-4b83-8ce2-b64d6478a063"},"colab":{},"outputId":"8bf8cf96-643f-42fd-c593-0dcadf950f74"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------+\n|value   |\n+--------+\n|alyssa.p|\n+--------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------+\n|value   |\n+--------+\n|alyssa.p|\n+--------+\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b83c068e-6f51-4c54-bc23-0007734e41a2"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["bad_status_df = null_status_df.select(regexp_extract('value', host_pattern, 1).alias('host'),\n                                      regexp_extract('value', ts_pattern, 1).alias('timestamp'),\n                                      regexp_extract('value', method_uri_protocol_pattern, 1).alias('method'),\n                                      regexp_extract('value', method_uri_protocol_pattern, 2).alias('endpoint'),\n                                      regexp_extract('value', method_uri_protocol_pattern, 3).alias('protocol'),\n                                      regexp_extract('value', status_pattern, 1).cast('integer').alias('status'),\n                                      regexp_extract('value', content_size_pattern, 1).cast('integer').alias('content_size'))\nbad_status_df.show(truncate=False)"],"metadata":{"colab_type":"code","id":"-ec9HtGwXvBh","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d50b2ff1-d1db-40ce-825e-07df9510378c"},"colab":{},"outputId":"9bc09049-3dff-4b65-8fec-5b7edf2cda39"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----+---------+------+--------+--------+------+------------+\n|host|timestamp|method|endpoint|protocol|status|content_size|\n+----+---------+------+--------+--------+------+------------+\n|    |         |      |        |        |null  |null        |\n+----+---------+------+--------+--------+------+------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+---------+------+--------+--------+------+------------+\n|host|timestamp|method|endpoint|protocol|status|content_size|\n+----+---------+------+--------+--------+------+------------+\n|    |         |      |        |        |null  |null        |\n+----+---------+------+--------+--------+------+------------+\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1a8ce23c-79cb-4756-b1b8-cb37c9a59f7c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Looks like the record itself is an incomplete record with no useful information, the best option would be to drop this record as follows!"],"metadata":{"colab_type":"text","id":"wS7tZXIUXvBk","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b0d25ebe-c473-454d-ab45-1faffccd1c98"}}},{"cell_type":"code","source":["logs_df.count()"],"metadata":{"colab_type":"code","id":"zb6wxLWuXvBl","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e75a690-3409-48e1-8e77-c807514481e1"},"colab":{},"outputId":"b4f36a5a-9679-4830-91fc-80388aac54e2"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[27]: 3461613","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[27]: 3461613"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8f28eedb-ca9b-4242-95a5-a57b7676d6cc"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["logs_df = logs_df[logs_df['status'].isNotNull()]\nlogs_df.count()"],"metadata":{"colab_type":"code","id":"RQogALLJXvBo","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"66640f55-c5f8-4cf2-8065-db7b3b311e3f"},"colab":{},"outputId":"41034dca-c862-48e7-9a3d-548738bebbff"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[28]: 3461613","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[28]: 3461613"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2cf208d1-8c25-4306-bfe5-451dcbb8ea0d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["exprs = [count_null(col_name) for col_name in logs_df.columns]\nlogs_df.agg(*exprs).show()"],"metadata":{"colab_type":"code","id":"_rHsvCeeXvBs","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bc4a11f5-6f13-44a4-98eb-599ed2178ea9"},"colab":{},"outputId":"a58d88c2-94cc-4c58-bf1f-bf12abc0e822"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----+---------+------+--------+--------+------+------------+\n|host|timestamp|method|endpoint|protocol|status|content_size|\n+----+---------+------+--------+--------+------+------------+\n|   0|        0|     0|       0|       0|     0|           0|\n+----+---------+------+--------+--------+------+------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+---------+------+--------+--------+------+------------+\n|host|timestamp|method|endpoint|protocol|status|content_size|\n+----+---------+------+--------+--------+------+------------+\n|   0|        0|     0|       0|       0|     0|           0|\n+----+---------+------+--------+--------+------+------------+\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9dc44b2b-4da1-46e0-bc33-7976abcc6b70"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Handling nulls in HTTP content size\n\nAgain based on our previous regular expression and assuming you were able to solve it correctly, our original parsing regular expression for the `content_size` column was:\n\n```\nregexp_extract('value', r'\\s(\\d+)$', 1).cast('integer').alias('content_size')\n``` \n\nCould there be missing data in our original dataset itself? Let's try and find out!"],"metadata":{"colab_type":"text","id":"8k4-PjEFXvBv","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b1284b2a-f948-4401-b527-08a4694af596"}}},{"cell_type":"markdown","source":["### Q2: Your Turn: Find out the records in our base data frame with potential missing content sizes\n\n- Use the `r'\\s\\d+$'` regex pattern with the `rlike()` function like we demonstrated in the previous example\n- Remember to work on `base_df` since we are searching on the raw records NOT the parsed `logs_df`\n- Find the total count of the records with missing content size in `base_df` using the `count()` function"],"metadata":{"colab_type":"text","id":"MMjHfm1aXvBw","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"babace2a-73a0-408b-abc9-bda93aeb95f9"}}},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\n\nnull_content_size_df = base_df.filter(~ base_df['value'].rlike(r'\\d+$'))\nnull_content_size_df.count()"],"metadata":{"colab_type":"code","id":"ki7G6daTXvBx","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0850e596-0038-44ee-9a34-72f6a54779a3"},"colab":{},"outputId":"8a7230f3-f87b-4681-fcfc-b5d9503a441d"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[30]: 33905","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[30]: 33905"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["### Q3: Your Turn: Display the top ten records of your data frame having missing content sizes"],"metadata":{"colab_type":"text","id":"6te6fSfCXvB0","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1d5ecf8c-f5b5-4efe-b8e0-ed94d74b6542"}}},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\n\nnull_content_size_df.take(10)"],"metadata":{"colab_type":"code","id":"P1vwVWX4XvB1","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b9d00439-02ca-4c57-bc22-5c2fa11e1cb3"},"colab":{},"outputId":"c11b52c6-ed73-421f-8988-8eb6296c7e7a"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[31]: [Row(value='dd15-062.compuserve.com - - [01/Jul/1995:00:01:12 -0400] \"GET /news/sci.space.shuttle/archive/sci-space-shuttle-22-apr-1995-40.txt HTTP/1.0\" 404 -'),\n Row(value='dynip42.efn.org - - [01/Jul/1995:00:02:14 -0400] \"GET /software HTTP/1.0\" 302 -'),\n Row(value='ix-or10-06.ix.netcom.com - - [01/Jul/1995:00:02:40 -0400] \"GET /software/winvn HTTP/1.0\" 302 -'),\n Row(value='ix-or10-06.ix.netcom.com - - [01/Jul/1995:00:03:24 -0400] \"GET /software HTTP/1.0\" 302 -'),\n Row(value='link097.txdirect.net - - [01/Jul/1995:00:05:06 -0400] \"GET /shuttle HTTP/1.0\" 302 -'),\n Row(value='ix-war-mi1-20.ix.netcom.com - - [01/Jul/1995:00:05:13 -0400] \"GET /shuttle/missions/sts-78/news HTTP/1.0\" 302 -'),\n Row(value='ix-war-mi1-20.ix.netcom.com - - [01/Jul/1995:00:05:58 -0400] \"GET /shuttle/missions/sts-72/news HTTP/1.0\" 302 -'),\n Row(value='netport-27.iu.net - - [01/Jul/1995:00:10:19 -0400] \"GET /pub/winvn/readme.txt HTTP/1.0\" 404 -'),\n Row(value='netport-27.iu.net - - [01/Jul/1995:00:10:28 -0400] \"GET /pub/winvn/readme.txt HTTP/1.0\" 404 -'),\n Row(value='dynip38.efn.org - - [01/Jul/1995:00:10:50 -0400] \"GET /software HTTP/1.0\" 302 -')]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[31]: [Row(value='dd15-062.compuserve.com - - [01/Jul/1995:00:01:12 -0400] \"GET /news/sci.space.shuttle/archive/sci-space-shuttle-22-apr-1995-40.txt HTTP/1.0\" 404 -'),\n Row(value='dynip42.efn.org - - [01/Jul/1995:00:02:14 -0400] \"GET /software HTTP/1.0\" 302 -'),\n Row(value='ix-or10-06.ix.netcom.com - - [01/Jul/1995:00:02:40 -0400] \"GET /software/winvn HTTP/1.0\" 302 -'),\n Row(value='ix-or10-06.ix.netcom.com - - [01/Jul/1995:00:03:24 -0400] \"GET /software HTTP/1.0\" 302 -'),\n Row(value='link097.txdirect.net - - [01/Jul/1995:00:05:06 -0400] \"GET /shuttle HTTP/1.0\" 302 -'),\n Row(value='ix-war-mi1-20.ix.netcom.com - - [01/Jul/1995:00:05:13 -0400] \"GET /shuttle/missions/sts-78/news HTTP/1.0\" 302 -'),\n Row(value='ix-war-mi1-20.ix.netcom.com - - [01/Jul/1995:00:05:58 -0400] \"GET /shuttle/missions/sts-72/news HTTP/1.0\" 302 -'),\n Row(value='netport-27.iu.net - - [01/Jul/1995:00:10:19 -0400] \"GET /pub/winvn/readme.txt HTTP/1.0\" 404 -'),\n Row(value='netport-27.iu.net - - [01/Jul/1995:00:10:28 -0400] \"GET /pub/winvn/readme.txt HTTP/1.0\" 404 -'),\n Row(value='dynip38.efn.org - - [01/Jul/1995:00:10:50 -0400] \"GET /software HTTP/1.0\" 302 -')]"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["Assuming you were able to get to the missing records above, it is quite evident that the bad raw data records correspond to error responses, where no content was sent back and the server emitted a \"`-`\" for the `content_size` field. \n\nSince we don't want to discard those rows from our analysis, let's impute or fill them to 0."],"metadata":{"colab_type":"text","id":"Rl3J6c5sXvB8","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2959d3dc-1a0b-4f41-8e9a-2c50e7746022"}}},{"cell_type":"markdown","source":["### Q4: Your Turn: Fix the rows with null content\\_size\n\nThe easiest solution is to replace the null values in `logs_df` with 0 like we discussed earlier. The Spark DataFrame API provides a set of functions and fields specifically designed for working with null values, among them:\n\n* [fillna()](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.fillna), which fills null values with specified non-null values.\n* [na](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.na), which returns a [DataFrameNaFunctions](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrameNaFunctions) object with many functions for operating on null columns.\n\nThere are several ways to invoke this function. The easiest is just to replace _all_ null columns with known values. But, for safety, it's better to pass a Python dictionary containing (column\\_name, value) mappings. That's what we'll do. A sample example from the documentation is depicted below\n\n```\n>>> df4.na.fill({'age': 50, 'name': 'unknown'}).show()\n+---+------+-------+\n|age|height|   name|\n+---+------+-------+\n| 10|    80|  Alice|\n|  5|  null|    Bob|\n| 50|  null|    Tom|\n| 50|  null|unknown|\n+---+------+-------+\n```\n\nNow use this function and fill all the missing values in the `content_size` field with 0!"],"metadata":{"colab_type":"text","id":"2y3iD47fXvCB","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aa72d1c1-7bdc-48da-acd4-b080ed19408a"}}},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\n\nlogs_df = logs_df.na.fill({'content_size': 0})"],"metadata":{"colab_type":"code","collapsed":true,"id":"_2w5KTE0XvCC","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"95b5a9b3-d5db-4669-9893-18370ebc374f"},"colab":{},"outputId":"df4d371c-1376-4616-e2c7-9e35ddccf80e"},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Now assuming you were able to fill in the missing values successfully in the previous question, we should have no missing values \\ nulls in our dataset. Let's verify this!"],"metadata":{"colab_type":"text","id":"zdjkzs6UXvCJ","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d52fa78e-0e85-436b-8877-cf14244919b2"}}},{"cell_type":"code","source":["exprs = [count_null(col_name) for col_name in logs_df.columns]\nlogs_df.agg(*exprs).show()"],"metadata":{"colab_type":"code","id":"wDaLqVZOXvCK","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b9ad9f51-91f8-4f87-95d0-44d65fd9adf7"},"colab":{},"outputId":"a3097bef-1d37-4213-a6e8-a52b08c27947"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+----+---------+------+--------+--------+------+------------+\n|host|timestamp|method|endpoint|protocol|status|content_size|\n+----+---------+------+--------+--------+------+------------+\n|   0|        0|     0|       0|       0|     0|           0|\n+----+---------+------+--------+--------+------+------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+----+---------+------+--------+--------+------+------------+\n|host|timestamp|method|endpoint|protocol|status|content_size|\n+----+---------+------+--------+--------+------+------------+\n|   0|        0|     0|       0|       0|     0|           0|\n+----+---------+------+--------+--------+------+------------+\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["Look at that, no missing values!"],"metadata":{"colab_type":"text","id":"Bjr1f1m2XvCN","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c7e4592f-e9a3-49e3-a0ec-5048cd8c33a8"}}},{"cell_type":"markdown","source":["## Handling Temporal Fields (Timestamp)\n\nNow that we have a clean, parsed DataFrame, we have to parse the timestamp field into an actual timestamp. The Common Log Format time is somewhat non-standard. A User-Defined Function (UDF) is the most straightforward way to parse it."],"metadata":{"colab_type":"text","id":"UFtYMGZhXvCN","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fca98db8-2e27-4b42-9c5e-668aafd41876"}}},{"cell_type":"code","source":["from pyspark.sql.functions import udf\n\nmonth_map = {\n  'Jan': 1, 'Feb': 2, 'Mar':3, 'Apr':4, 'May':5, 'Jun':6, 'Jul':7,\n  'Aug':8,  'Sep': 9, 'Oct':10, 'Nov': 11, 'Dec': 12\n}\n\ndef parse_clf_time(text):\n    \"\"\" Convert Common Log time format into a Python datetime object\n    Args:\n        text (str): date and time in Apache time format [dd/mmm/yyyy:hh:mm:ss (+/-)zzzz]\n    Returns:\n        a string suitable for passing to CAST('timestamp')\n    \"\"\"\n    # NOTE: We're ignoring time zone here. In a production application, you'd want to handle that.\n    return \"{0:04d}-{1:02d}-{2:02d} {3:02d}:{4:02d}:{5:02d}\".format(\n      int(text[7:11]),\n      month_map[text[3:6]],\n      int(text[0:2]),\n      int(text[12:14]),\n      int(text[15:17]),\n      int(text[18:20])\n    )"],"metadata":{"colab_type":"code","id":"k5t5VysnXvCS","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"63fc8a7c-b75d-4520-832c-58b7e0563fef"},"colab":{},"outputId":"bebe2bb0-65ec-4d43-dbc9-24cda3c32de0"},"outputs":[],"execution_count":0},{"cell_type":"code","source":["sample_ts = [item['timestamp'] for item in logs_df.select('timestamp').take(5)]\nsample_ts"],"metadata":{"colab_type":"code","id":"RLJHPXHwXvCW","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f9b0ab5e-8fb4-4e39-9344-82e75e42fb40"},"colab":{},"outputId":"2e58d673-3c1b-45fa-f283-886c698cfc6d"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[35]: ['01/Jul/1995:00:00:01 -0400',\n '01/Jul/1995:00:00:06 -0400',\n '01/Jul/1995:00:00:09 -0400',\n '01/Jul/1995:00:00:11 -0400',\n '01/Jul/1995:00:00:11 -0400']","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[35]: ['01/Jul/1995:00:00:01 -0400',\n '01/Jul/1995:00:00:06 -0400',\n '01/Jul/1995:00:00:09 -0400',\n '01/Jul/1995:00:00:11 -0400',\n '01/Jul/1995:00:00:11 -0400']"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5df7b1e0-453f-4301-8215-08642cd5e285"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["[parse_clf_time(item) for item in sample_ts]"],"metadata":{"colab_type":"code","id":"0K5Yd1Z2XvCY","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"010f7864-3f7a-4f7a-a9b0-89a7799ddca4"},"colab":{},"outputId":"6108f5bb-bbd8-4c11-f9e4-efc491c543e0"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[36]: ['1995-07-01 00:00:01',\n '1995-07-01 00:00:06',\n '1995-07-01 00:00:09',\n '1995-07-01 00:00:11',\n '1995-07-01 00:00:11']","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[36]: ['1995-07-01 00:00:01',\n '1995-07-01 00:00:06',\n '1995-07-01 00:00:09',\n '1995-07-01 00:00:11',\n '1995-07-01 00:00:11']"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7dc2c811-4b94-43f7-973c-874940c94444"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["udf_parse_time = udf(parse_clf_time)\n\nlogs_df = logs_df.select('*', udf_parse_time(logs_df['timestamp']).cast('timestamp').alias('time')).drop('timestamp')\nlogs_df.show(10, truncate=True)"],"metadata":{"colab_type":"code","id":"WBbQ_QNsXvCb","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"978c8f59-d1e3-46ed-8b99-bd85066fa8b2"},"colab":{},"outputId":"b1e05731-4bff-410d-8c6f-d1637fd0f0a7"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+------+--------------------+--------+------+------------+-------------------+\n|                host|method|            endpoint|protocol|status|content_size|               time|\n+--------------------+------+--------------------+--------+------+------------+-------------------+\n|        199.72.81.55|   GET|    /history/apollo/|HTTP/1.0|   200|        6245|1995-07-01 00:00:01|\n|unicomp6.unicomp.net|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|1995-07-01 00:00:06|\n|      199.120.110.21|   GET|/shuttle/missions...|HTTP/1.0|   200|        4085|1995-07-01 00:00:09|\n|  burger.letters.com|   GET|/shuttle/countdow...|HTTP/1.0|   304|           0|1995-07-01 00:00:11|\n|      199.120.110.21|   GET|/shuttle/missions...|HTTP/1.0|   200|        4179|1995-07-01 00:00:11|\n|  burger.letters.com|   GET|/images/NASA-logo...|HTTP/1.0|   304|           0|1995-07-01 00:00:12|\n|  burger.letters.com|   GET|/shuttle/countdow...|HTTP/1.0|   200|           0|1995-07-01 00:00:12|\n|     205.212.115.106|   GET|/shuttle/countdow...|HTTP/1.0|   200|        3985|1995-07-01 00:00:12|\n|         d104.aa.net|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|1995-07-01 00:00:13|\n|      129.94.144.152|   GET|                   /|HTTP/1.0|   200|        7074|1995-07-01 00:00:13|\n+--------------------+------+--------------------+--------+------+------------+-------------------+\nonly showing top 10 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+------+--------------------+--------+------+------------+-------------------+\n|                host|method|            endpoint|protocol|status|content_size|               time|\n+--------------------+------+--------------------+--------+------+------------+-------------------+\n|        199.72.81.55|   GET|    /history/apollo/|HTTP/1.0|   200|        6245|1995-07-01 00:00:01|\n|unicomp6.unicomp.net|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|1995-07-01 00:00:06|\n|      199.120.110.21|   GET|/shuttle/missions...|HTTP/1.0|   200|        4085|1995-07-01 00:00:09|\n|  burger.letters.com|   GET|/shuttle/countdow...|HTTP/1.0|   304|           0|1995-07-01 00:00:11|\n|      199.120.110.21|   GET|/shuttle/missions...|HTTP/1.0|   200|        4179|1995-07-01 00:00:11|\n|  burger.letters.com|   GET|/images/NASA-logo...|HTTP/1.0|   304|           0|1995-07-01 00:00:12|\n|  burger.letters.com|   GET|/shuttle/countdow...|HTTP/1.0|   200|           0|1995-07-01 00:00:12|\n|     205.212.115.106|   GET|/shuttle/countdow...|HTTP/1.0|   200|        3985|1995-07-01 00:00:12|\n|         d104.aa.net|   GET| /shuttle/countdown/|HTTP/1.0|   200|        3985|1995-07-01 00:00:13|\n|      129.94.144.152|   GET|                   /|HTTP/1.0|   200|        7074|1995-07-01 00:00:13|\n+--------------------+------+--------------------+--------+------+------------+-------------------+\nonly showing top 10 rows\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"834562a5-584b-40ae-8203-8d074ef020a3"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["logs_df.printSchema()"],"metadata":{"colab_type":"code","id":"9Yy-eIDtXvCi","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7a7d160a-14f5-4c42-8be2-f40536c15599"},"colab":{},"outputId":"913a1185-f22d-4ac9-856b-d31db17eca28"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- host: string (nullable = true)\n |-- method: string (nullable = true)\n |-- endpoint: string (nullable = true)\n |-- protocol: string (nullable = true)\n |-- status: string (nullable = true)\n |-- content_size: string (nullable = false)\n |-- time: timestamp (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- host: string (nullable = true)\n |-- method: string (nullable = true)\n |-- endpoint: string (nullable = true)\n |-- protocol: string (nullable = true)\n |-- status: string (nullable = true)\n |-- content_size: string (nullable = false)\n |-- time: timestamp (nullable = true)\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a3b0bf5d-def6-48dd-a7b9-74f5e35686ba"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["logs_df.limit(5).toPandas()"],"metadata":{"colab_type":"code","id":"wfMB_2JvXvCk","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"69246da1-923f-4d2f-8fff-5ca2158c3d2e"},"colab":{},"outputId":"dfb9673b-af0c-4232-d28f-674fa1662ac0"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>host</th>\n      <th>method</th>\n      <th>endpoint</th>\n      <th>protocol</th>\n      <th>status</th>\n      <th>content_size</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>199.72.81.55</td>\n      <td>GET</td>\n      <td>/history/apollo/</td>\n      <td>HTTP/1.0</td>\n      <td>200</td>\n      <td>6245</td>\n      <td>1995-07-01 00:00:01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>unicomp6.unicomp.net</td>\n      <td>GET</td>\n      <td>/shuttle/countdown/</td>\n      <td>HTTP/1.0</td>\n      <td>200</td>\n      <td>3985</td>\n      <td>1995-07-01 00:00:06</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>199.120.110.21</td>\n      <td>GET</td>\n      <td>/shuttle/missions/sts-73/mission-sts-73.html</td>\n      <td>HTTP/1.0</td>\n      <td>200</td>\n      <td>4085</td>\n      <td>1995-07-01 00:00:09</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>burger.letters.com</td>\n      <td>GET</td>\n      <td>/shuttle/countdown/liftoff.html</td>\n      <td>HTTP/1.0</td>\n      <td>304</td>\n      <td>0</td>\n      <td>1995-07-01 00:00:11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>199.120.110.21</td>\n      <td>GET</td>\n      <td>/shuttle/missions/sts-73/sts-73-patch-small.gif</td>\n      <td>HTTP/1.0</td>\n      <td>200</td>\n      <td>4179</td>\n      <td>1995-07-01 00:00:11</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>host</th>\n      <th>method</th>\n      <th>endpoint</th>\n      <th>protocol</th>\n      <th>status</th>\n      <th>content_size</th>\n      <th>time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>199.72.81.55</td>\n      <td>GET</td>\n      <td>/history/apollo/</td>\n      <td>HTTP/1.0</td>\n      <td>200</td>\n      <td>6245</td>\n      <td>1995-07-01 00:00:01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>unicomp6.unicomp.net</td>\n      <td>GET</td>\n      <td>/shuttle/countdown/</td>\n      <td>HTTP/1.0</td>\n      <td>200</td>\n      <td>3985</td>\n      <td>1995-07-01 00:00:06</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>199.120.110.21</td>\n      <td>GET</td>\n      <td>/shuttle/missions/sts-73/mission-sts-73.html</td>\n      <td>HTTP/1.0</td>\n      <td>200</td>\n      <td>4085</td>\n      <td>1995-07-01 00:00:09</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>burger.letters.com</td>\n      <td>GET</td>\n      <td>/shuttle/countdown/liftoff.html</td>\n      <td>HTTP/1.0</td>\n      <td>304</td>\n      <td>0</td>\n      <td>1995-07-01 00:00:11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>199.120.110.21</td>\n      <td>GET</td>\n      <td>/shuttle/missions/sts-73/sts-73-patch-small.gif</td>\n      <td>HTTP/1.0</td>\n      <td>200</td>\n      <td>4179</td>\n      <td>1995-07-01 00:00:11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b981aa57-d7a1-46d0-8803-897585b2bcdc"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's now cache `logs_df` since we will be using it extensively for our data analysis section in the next part!"],"metadata":{"colab_type":"text","id":"cn3ghlDsXvCp","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"07abc755-d208-462d-a5fb-81668a2d2ac8"}}},{"cell_type":"markdown","source":["# Step 2 - Exploratory Data Analysis on our Web Logs\n\nNow that we have a DataFrame containing the parsed log file as a data frame, we can perform some interesting exploratory data analysis (EDA)\n\n## Example: Content Size Statistics\n\nLet's compute some statistics about the sizes of content being returned by the web server. In particular, we'd like to know what are the average, minimum, and maximum content sizes.\n\nWe can compute the statistics by calling `.describe()` on the `content_size` column of `logs_df`.  The `.describe()` function returns the count, mean, stddev, min, and max of a given column."],"metadata":{"colab_type":"text","id":"1WTHkvANXvCq","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41c8c030-2d09-4ea4-9f99-a5b2a79acf70"}}},{"cell_type":"code","source":["content_size_summary_df = logs_df.describe(['content_size'])\ncontent_size_summary_df.toPandas()"],"metadata":{"colab_type":"code","id":"FHkVy3ZXXvCr","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e2b4742f-fe90-45b3-93bd-4194500eca1a"},"colab":{},"outputId":"cd083d90-c450-4d64-9d56-c8e1f5dd1eed"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>summary</th>\n      <th>content_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>count</td>\n      <td>3461613</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mean</td>\n      <td>19116.072581153352</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>stddev</td>\n      <td>73367.3795143063</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>min</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max</td>\n      <td>99981</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>summary</th>\n      <th>content_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>count</td>\n      <td>3461613</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mean</td>\n      <td>19116.072581153352</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>stddev</td>\n      <td>73367.3795143063</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>min</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max</td>\n      <td>99981</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e24ab0b5-b370-4333-a147-eca557e826f9"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Alternatively, we can use SQL to directly calculate these statistics.  You can explore many useful functions within the `pyspark.sql.functions` module in the [documentation](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions).\n\nAfter we apply the `.agg()` function, we call `toPandas()` to extract and convert the result into a `pandas` dataframe which has better formatting on Jupyter notebooks"],"metadata":{"colab_type":"text","id":"fY1S9FPAXvCv","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eaa203c7-60a1-4193-af91-9a08fa4e9e98"}}},{"cell_type":"code","source":["from pyspark.sql import functions as F\n\n(logs_df.agg(F.min(logs_df['content_size']).alias('min_content_size'),\n             F.max(logs_df['content_size']).alias('max_content_size'),\n             F.mean(logs_df['content_size']).alias('mean_content_size'),\n             F.stddev(logs_df['content_size']).alias('std_content_size'),\n             F.count(logs_df['content_size']).alias('count_content_size'))\n        .toPandas())"],"metadata":{"colab_type":"code","id":"nonAax8AXvCx","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0fb5e1dd-2930-4f95-9129-5c8daebf04e7"},"colab":{},"outputId":"1a9a01ac-35f3-44ab-f105-5759f8f79b9a"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>min_content_size</th>\n      <th>max_content_size</th>\n      <th>mean_content_size</th>\n      <th>std_content_size</th>\n      <th>count_content_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>99981</td>\n      <td>19116.072581</td>\n      <td>73367.379514</td>\n      <td>3461613</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>min_content_size</th>\n      <th>max_content_size</th>\n      <th>mean_content_size</th>\n      <th>std_content_size</th>\n      <th>count_content_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>99981</td>\n      <td>19116.072581</td>\n      <td>73367.379514</td>\n      <td>3461613</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f8d36613-8b59-4523-808e-eb60ad17ac4d"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Example: HTTP Status Code Analysis\n\nNext, let's look at the status code values that appear in the log. We want to know which status code values appear in the data and how many times.  \n\nWe again start with `logs_df`, then group by the `status` column, apply the `.count()` aggregation function, and sort by the `status` column."],"metadata":{"colab_type":"text","id":"8hat3HPwXvC0","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"03dbf2f4-63dd-4462-84b9-92ba7c086d0a"}}},{"cell_type":"code","source":["status_freq_df = (logs_df\n                     .groupBy('status')\n                     .count()\n                     .sort('status')\n                     .cache())"],"metadata":{"colab_type":"code","collapsed":true,"id":"jL-vEt0FXvC1","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"84a7a52a-3cb9-4233-9430-b20dfe9c8711"},"colab":{},"outputId":"8ee8079f-8b03-4e70-8335-cbd7b2d0b1bc"},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5d2e5ab4-f90b-487f-ba0b-6ae83abeb163"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"450a1b74-ece8-4c8c-b54d-134b4b986551"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["print('Total distinct HTTP Status Codes:', status_freq_df.count())"],"metadata":{"colab_type":"code","id":"a0iPsCW2XvC3","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e15888c9-ca2e-46dc-bb10-41e61daa2856"},"colab":{},"outputId":"64fbd3f8-cf08-4ca3-de33-32349d3d6597"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Total distinct HTTP Status Codes: 9\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Total distinct HTTP Status Codes: 9\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["status_freq_pd_df = status_freq_df.toPandas()\nstatus_freq_pd_df"],"metadata":{"colab_type":"code","id":"SZO7ncjdXvC6","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dd67bf9c-5ceb-4f7e-9805-3b3ff27cd9c1"},"colab":{},"outputId":"0344aef8-367b-476b-fc2c-e6c1346d3da9"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>status</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>200</td>\n      <td>3100524</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>302</td>\n      <td>73070</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>304</td>\n      <td>266773</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>400</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>403</td>\n      <td>225</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>404</td>\n      <td>20899</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>500</td>\n      <td>65</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>501</td>\n      <td>41</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>status</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>200</td>\n      <td>3100524</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>302</td>\n      <td>73070</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>304</td>\n      <td>266773</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>400</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>403</td>\n      <td>225</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>404</td>\n      <td>20899</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>500</td>\n      <td>65</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>501</td>\n      <td>41</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"90d9845f-5281-49f1-a3bf-1351b0da2e41"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b25f7d21-1993-4166-9087-3e4639337167"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n%matplotlib inline\n\nstatus_freq_pd_df.plot(x='status', y='count', kind='bar')"],"metadata":{"colab":{},"colab_type":"code","id":"KXkKQA-WXvC8","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b65d2c10-b306-4562-b40d-2650791f0961"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[45]: <AxesSubplot:xlabel='status'>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[45]: <AxesSubplot:xlabel='status'>"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"data:image/png;base64,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\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"image","arguments":{}}},"output_type":"display_data","data":{"image/png":"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\n"},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b36dae4e-9581-49b0-b410-e08c7d349f43"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["log_freq_df = status_freq_df.withColumn('log(count)', F.log(status_freq_df['count']))\nlog_freq_df.show()"],"metadata":{"colab_type":"code","id":"iabid8S6XvC_","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f54ff6a2-3687-4be1-b877-557f7388227b"},"colab":{},"outputId":"31df7ac0-35f9-4f9e-f059-c4267865c9b6"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+------+-------+------------------+\n|status|  count|        log(count)|\n+------+-------+------------------+\n|      |      1|               0.0|\n|   200|3100524|14.947081687429097|\n|   302|  73070|11.199173164785263|\n|   304| 266773|12.494153388502301|\n|   400|     15|  2.70805020110221|\n|   403|    225|  5.41610040220442|\n|   404|  20899| 9.947456589918252|\n|   500|     65| 4.174387269895637|\n|   501|     41| 3.713572066704308|\n+------+-------+------------------+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+------+-------+------------------+\n|status|  count|        log(count)|\n+------+-------+------------------+\n|      |      1|               0.0|\n|   200|3100524|14.947081687429097|\n|   302|  73070|11.199173164785263|\n|   304| 266773|12.494153388502301|\n|   400|     15|  2.70805020110221|\n|   403|    225|  5.41610040220442|\n|   404|  20899| 9.947456589918252|\n|   500|     65| 4.174387269895637|\n|   501|     41| 3.713572066704308|\n+------+-------+------------------+\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["#### Q5: Your Turn: Convert the log\\_freq\\_df to a pandas DataFrame and plot a bar chart displaying counts of each HTTP Status Code"],"metadata":{"colab_type":"text","id":"CWcfTjlUXvDC","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6646df73-9369-404a-a28a-cd0363492d33"}}},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\nlog_freq_pd_df = log_freq_df.toPandas()\nlog_freq_pd_df.plot(x='status', y='count', kind='bar')"],"metadata":{"colab":{},"colab_type":"code","id":"RWWwF5NcXvDD","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"90058257-ad92-47f9-894e-0182e1a966c4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[47]: <AxesSubplot:xlabel='status'>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[47]: <AxesSubplot:xlabel='status'>"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"data:image/png;base64,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\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"image","arguments":{}}},"output_type":"display_data","data":{"image/png":"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\n"},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Your Turn: Q6: Analyzing Frequent Hosts\n\nLet's look at hosts that have accessed the server frequently. Try to get the count of total accesses by each `host` and then sort by the counts and display only the top ten most frequent hosts.\n\n__Hints:__\n\n- Your Spark DataFrame has a `host` column\n- Get the counts per `host` which would make a `count` column\n- Sort by the counts. Please check [__the documentation__](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame.sort) to see how to sort in reverse\n- Remember only to get the top 10 rows from the aggregated dataframe and show them"],"metadata":{"colab_type":"text","id":"k5oXMLxSXvDH","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e8397599-a43b-46bf-b9f1-055de10f25aa"}}},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\n\nhost_freq_df = logs_df.groupBy('host').count().cache()\nhost_sum_df = host_freq_df.filter(host_freq_df['count']>10).select(host_freq_df['host'])\n\nhost_sum_df.show(truncate=False)"],"metadata":{"colab_type":"code","id":"eBBayokUXvDM","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"099fc977-998e-4d12-a952-18b9822a7800"},"colab":{},"outputId":"83a26ad7-21c2-4b15-b527-5de9ac5b8c5c"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------------------------+\n|host                       |\n+---------------------------+\n|ppp3_136.bekkoame.or.jp    |\n|ppp31.texoma.com           |\n|ix-wc7-20.ix.netcom.com    |\n|nb1-du5.polarnet.fnsb.ak.us|\n|ttyb5.shasta.com           |\n|dd14-025.compuserve.com    |\n|uckm001.pn.itnet.it        |\n|queulen.puc.cl             |\n|pipe2.nyc.pipeline.com     |\n|198.53.164.131             |\n|asdsun.larc.nasa.gov       |\n|194.20.34.120              |\n|dd09-021.compuserve.com    |\n|freenet.carleton.ca        |\n|enigma.idirect.com         |\n|slip-3-28.shore.net        |\n|port-1-3.access.one.net    |\n|ip157.vivanet.com          |\n|carober.illuminet.net      |\n|theory.caltech.edu         |\n+---------------------------+\nonly showing top 20 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------------------------+\n|host                       |\n+---------------------------+\n|ppp3_136.bekkoame.or.jp    |\n|ppp31.texoma.com           |\n|ix-wc7-20.ix.netcom.com    |\n|nb1-du5.polarnet.fnsb.ak.us|\n|ttyb5.shasta.com           |\n|dd14-025.compuserve.com    |\n|uckm001.pn.itnet.it        |\n|queulen.puc.cl             |\n|pipe2.nyc.pipeline.com     |\n|198.53.164.131             |\n|asdsun.larc.nasa.gov       |\n|194.20.34.120              |\n|dd09-021.compuserve.com    |\n|freenet.carleton.ca        |\n|enigma.idirect.com         |\n|slip-3-28.shore.net        |\n|port-1-3.access.one.net    |\n|ip157.vivanet.com          |\n|carober.illuminet.net      |\n|theory.caltech.edu         |\n+---------------------------+\nonly showing top 20 rows\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["host_sum_pd_df = host_sum_df.toPandas()\nhost_sum_pd_df.iloc[8]['host']"],"metadata":{"colab_type":"code","id":"1dv8Ny3iXvDQ","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6d568f8b-0b0b-48e0-bbbe-e285359eaefc"},"colab":{},"outputId":"ea532f95-2ff4-4e36-abc5-36297902d8e6"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[49]: 'pipe2.nyc.pipeline.com'","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[49]: 'pipe2.nyc.pipeline.com'"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["Looks like we have some empty strings as one of the top host names! This teaches us a valuable lesson to not just check for nulls but also potentially empty strings when data wrangling."],"metadata":{"colab_type":"text","id":"qJNpJU2VXvDT","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f0fc5ed1-bacd-4d61-a40c-162c1745fa73"}}},{"cell_type":"markdown","source":["## Your Turn: Q7: Display the Top 20 Frequent EndPoints\n\nNow, let's visualize the number of hits to endpoints (URIs) in the log. To perform this task, start with our `logs_df` and group by the `endpoint` column, aggregate by count, and sort in descending order like the previous question. Also remember to show only the top 20 most frequently accessed endpoints"],"metadata":{"colab_type":"text","id":"Pq5jiBtIXvDU","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9e0ccd2c-58e6-43cf-b9be-72f1f85fa6ca"}}},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\n\npaths_df = logs_df.groupBy('endpoint').count().sort('count', ascending=False)"],"metadata":{"colab_type":"code","id":"oxZRXX-AXvDU","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"111bd0b8-719a-4d8f-abe9-efc1813f4d17"},"colab":{},"outputId":"bae76bd6-6f67-478c-ea46-928f545cf4bc"},"outputs":[],"execution_count":0},{"cell_type":"code","source":["paths_pd_df = paths_df.toPandas()\npaths_pd_df"],"metadata":{"colab_type":"code","id":"DwfjJG2jXvDX","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"561d283b-0cf0-43a9-ab92-ce80d99c34cd"},"colab":{},"outputId":"d44c9385-5a6b-4157-83bc-d4d6832cc6a6"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>endpoint</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/images/NASA-logosmall.gif</td>\n      <td>208714</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/images/KSC-logosmall.gif</td>\n      <td>164970</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/images/MOSAIC-logosmall.gif</td>\n      <td>127908</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/images/USA-logosmall.gif</td>\n      <td>127074</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/images/WORLD-logosmall.gif</td>\n      <td>125925</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>31025</th>\n      <td>/htbin/wais.pl?raley</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31026</th>\n      <td>/cgi-bin/imagemap/countdown69?84,221</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31027</th>\n      <td>/cgi-bin/imagemap/fr?306,252</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31028</th>\n      <td>/htbin/wais.pl?artificial</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31029</th>\n      <td>/cgi-bin/imagemap/countdown69?355,275</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>31030 rows  2 columns</p>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>endpoint</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/images/NASA-logosmall.gif</td>\n      <td>208714</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/images/KSC-logosmall.gif</td>\n      <td>164970</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/images/MOSAIC-logosmall.gif</td>\n      <td>127908</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/images/USA-logosmall.gif</td>\n      <td>127074</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/images/WORLD-logosmall.gif</td>\n      <td>125925</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>31025</th>\n      <td>/htbin/wais.pl?raley</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31026</th>\n      <td>/cgi-bin/imagemap/countdown69?84,221</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31027</th>\n      <td>/cgi-bin/imagemap/fr?306,252</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31028</th>\n      <td>/htbin/wais.pl?artificial</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>31029</th>\n      <td>/cgi-bin/imagemap/countdown69?355,275</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>31030 rows  2 columns</p>\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Your Turn: Q8: Top Ten Error Endpoints\n\nWhat are the top ten endpoints requested which did not have return code 200 (HTTP Status OK)? \n\nCreate a sorted list containing the endpoints and the number of times that they were accessed with a non-200 return code and show the top ten.\n\nThink about the steps that you need to perform to determine which endpoints did not have a 200 return code (combination of filtering, grouping, sorting and selecting the top ten aggregated records)"],"metadata":{"colab_type":"text","id":"LrK4j5aIXvDb","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"89e2c788-c1d7-4dbe-b752-a7ab17f3b342"}}},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\n\nnot200_df = logs_df.filter(logs_df['status']!=200)\n\nerror_endpoints_freq_df = not200_df.groupby('endpoint').count().sort('count', ascending=False).limit(10)\n                          "],"metadata":{"colab_type":"code","id":"s57_3ODMXvDc","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"886fdaa9-5b9e-4048-97a4-0a32ddd20223"},"colab":{},"outputId":"d25e0c40-eaff-459a-9fd4-40666e226d28"},"outputs":[],"execution_count":0},{"cell_type":"code","source":["error_endpoints_freq_df.show(truncate=False)"],"metadata":{"colab_type":"code","id":"GeAUAEMBXvDh","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aa51fe09-1cbf-46f8-b6c0-7da955bd7b0d"},"colab":{},"outputId":"a5bc7840-a464-47ae-f014-9e3108c2b306"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---------------------------------------+-----+\n|endpoint                               |count|\n+---------------------------------------+-----+\n|/images/NASA-logosmall.gif             |40082|\n|/images/KSC-logosmall.gif              |23763|\n|/images/MOSAIC-logosmall.gif           |15245|\n|/images/USA-logosmall.gif              |15142|\n|/images/WORLD-logosmall.gif            |14773|\n|/images/ksclogo-medium.gif             |13559|\n|/images/launch-logo.gif                |8806 |\n|/history/apollo/images/apollo-logo1.gif|7489 |\n|/                                      |6296 |\n|/images/ksclogosmall.gif               |5669 |\n+---------------------------------------+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---------------------------------------+-----+\n|endpoint                               |count|\n+---------------------------------------+-----+\n|/images/NASA-logosmall.gif             |40082|\n|/images/KSC-logosmall.gif              |23763|\n|/images/MOSAIC-logosmall.gif           |15245|\n|/images/USA-logosmall.gif              |15142|\n|/images/WORLD-logosmall.gif            |14773|\n|/images/ksclogo-medium.gif             |13559|\n|/images/launch-logo.gif                |8806 |\n|/history/apollo/images/apollo-logo1.gif|7489 |\n|/                                      |6296 |\n|/images/ksclogosmall.gif               |5669 |\n+---------------------------------------+-----+\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Example: Number of Unique Daily Hosts\n\nFor an advanced example, let's look at a way to determine the number of unique hosts in the entire log on a day-by-day basis. This computation will give us counts of the number of unique daily hosts. \n\nWe'd like a DataFrame sorted by increasing day of the month which includes the day of the month and the associated number of unique hosts for that day. \n\nThink about the steps that you need to perform to count the number of different hosts that make requests *each* day.\n*Since the log only covers a single month, you can ignore the month.*  You may want to use the [`dayofmonth` function](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.dayofmonth) in the `pyspark.sql.functions` module (which we have already imported as __`F`__.\n\n\n**`host_day_df`**\n\nA DataFrame with two columns\n\n| column | explanation          |\n| ------ | -------------------- |\n| `host` | the host name        |\n| `day`  | the day of the month |\n\nThere will be one row in this DataFrame for each row in `logs_df`. Essentially, we are just transforming each row of `logs_df`. For example, for this row in `logs_df`:\n\n```\nunicomp6.unicomp.net - - [01/Aug/1995:00:35:41 -0400] \"GET /shuttle/missions/sts-73/news HTTP/1.0\" 302 -\n```\n\nyour `host_day_df` should have:\n\n```\nunicomp6.unicomp.net 1\n```"],"metadata":{"colab_type":"text","id":"ij1wJnMwXvDm","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1a4b55d3-e662-4e51-95ca-331d6d2f1ba7"}}},{"cell_type":"code","source":["host_day_df = logs_df.select(logs_df.host, \n                             F.dayofmonth('time').alias('day'))\nhost_day_df.show(5, truncate=False)"],"metadata":{"colab_type":"code","id":"c0i7-gm9XvDm","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f89dd092-dc5d-443a-a3e4-488e17e145eb"},"colab":{},"outputId":"ef93f5a2-e15d-4631-cbb7-e390dd0c28f0"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+---+\n|host                |day|\n+--------------------+---+\n|199.72.81.55        |1  |\n|unicomp6.unicomp.net|1  |\n|199.120.110.21      |1  |\n|burger.letters.com  |1  |\n|199.120.110.21      |1  |\n+--------------------+---+\nonly showing top 5 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+---+\n|host                |day|\n+--------------------+---+\n|199.72.81.55        |1  |\n|unicomp6.unicomp.net|1  |\n|199.120.110.21      |1  |\n|burger.letters.com  |1  |\n|199.120.110.21      |1  |\n+--------------------+---+\nonly showing top 5 rows\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["**`host_day_distinct_df`**\n\nThis DataFrame has the same columns as `host_day_distinct_df`, but with duplicate (`day`, `host`) rows removed."],"metadata":{"colab_type":"text","id":"HRu_5V4bXvDs","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"86318d5b-906f-42dc-be9f-44de6cb1ff7a"}}},{"cell_type":"code","source":["host_day_distinct_df = (host_day_df\n                          .dropDuplicates())\nhost_day_distinct_df.show(5, truncate=False)"],"metadata":{"colab_type":"code","id":"be9KD86vXvDt","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"164a82dd-b6bd-4ca8-83cb-77f5da8f1f5a"},"colab":{},"outputId":"013470c7-93ab-4c4a-945a-af4c212c85d7"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+---+\n|host                |day|\n+--------------------+---+\n|d104.aa.net         |1  |\n|199.72.81.55        |1  |\n|199.120.110.21      |1  |\n|205.212.115.106     |1  |\n|unicomp6.unicomp.net|1  |\n+--------------------+---+\nonly showing top 5 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+---+\n|host                |day|\n+--------------------+---+\n|d104.aa.net         |1  |\n|199.72.81.55        |1  |\n|199.120.110.21      |1  |\n|205.212.115.106     |1  |\n|unicomp6.unicomp.net|1  |\n+--------------------+---+\nonly showing top 5 rows\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["print(host_day_distinct_df.show())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7a30998-7885-4244-86a4-7d9d6b63eb59"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+---+\n|                host|day|\n+--------------------+---+\n|      129.94.144.152|  1|\n|  alyssa.prodigy.com|  1|\n|         d104.aa.net|  1|\n|        199.72.81.55|  1|\n|      205.189.154.54|  1|\n|ix-orl2-01.ix.net...|  1|\n|    dial22.lloyd.com|  1|\n|      199.120.110.21|  1|\n|port26.annex2.nwl...|  1|\n|     205.212.115.106|  1|\n|smyth-pc.moorecap...|  1|\n|unicomp6.unicomp.net|  1|\n|ppp-mia-30.shadow...|  1|\n| ppp-nyc-3-1.ios.com|  1|\n|gayle-gaston.tene...|  1|\n|  net-1-141.eden.com|  1|\n|waters-gw.starway...|  1|\n|   scheyer.clark.net|  1|\n|  burger.letters.com|  1|\n|piweba3y.prodigy.com|  1|\n+--------------------+---+\nonly showing top 20 rows\n\nNone\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+---+\n|                host|day|\n+--------------------+---+\n|      129.94.144.152|  1|\n|  alyssa.prodigy.com|  1|\n|         d104.aa.net|  1|\n|        199.72.81.55|  1|\n|      205.189.154.54|  1|\n|ix-orl2-01.ix.net...|  1|\n|    dial22.lloyd.com|  1|\n|      199.120.110.21|  1|\n|port26.annex2.nwl...|  1|\n|     205.212.115.106|  1|\n|smyth-pc.moorecap...|  1|\n|unicomp6.unicomp.net|  1|\n|ppp-mia-30.shadow...|  1|\n| ppp-nyc-3-1.ios.com|  1|\n|gayle-gaston.tene...|  1|\n|  net-1-141.eden.com|  1|\n|waters-gw.starway...|  1|\n|   scheyer.clark.net|  1|\n|  burger.letters.com|  1|\n|piweba3y.prodigy.com|  1|\n+--------------------+---+\nonly showing top 20 rows\n\nNone\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["**`daily_unique_hosts_df`**\n\nA DataFrame with two columns:\n\n| column  | explanation                                        |\n| ------- | -------------------------------------------------- |\n| `day`   | the day of the month                               |\n| `count` | the number of unique requesting hosts for that day |"],"metadata":{"colab_type":"text","id":"OlCEA952XvDv","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"baa8c0b4-80a7-4fb7-9a12-ec5fce654832"}}},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f5395d4a-71e2-41ca-9478-b5e11336fef0"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["daily_hosts_df = (host_day_distinct_df\n                     .groupby(\"day\")\n                     .count()\n                     .sort(\"day\"))\ndaily_hosts_df = daily_hosts_df.toPandas()\ndaily_hosts_df.T"],"metadata":{"colab_type":"code","id":"TrVQJOKPXvDv","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c7b6a39b-6f6b-47f2-ab29-83e070e2a188"},"colab":{},"outputId":"875f282f-13f6-4f9c-b4ee-a8f867f2955f"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/databricks/spark/python/pyspark/sql/pandas/conversion.py:161: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true, but has reached the error below and can not continue. Note that 'spark.sql.execution.arrow.pyspark.fallback.enabled' does not have an effect on failures in the middle of computation.\n  An error occurred while calling o3153.getResult.\n: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:428)\n\tat org.apache.spark.security.SocketAuthServer.getResult(SocketAuthServer.scala:107)\n\tat org.apache.spark.security.SocketAuthServer.getResult(SocketAuthServer.scala:103)\n\tat sun.reflect.GeneratedMethodAccessor622.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 183.0 failed 1 times, most recent failure: Lost task 0.0 in stage 183.0 (TID 813) (ip-10-172-192-231.us-west-2.compute.internal executor driver): org.apache.spark.api.python.PythonException: 'ValueError: invalid literal for int() with base 10: ''', from <command-3048127638877849>, line 17. Full traceback below:\nTraceback (most recent call last):\n  File \"<command-3048127638877849>\", line 17, in parse_clf_time\nValueError: invalid literal for int() with base 10: ''\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:689)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:642)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:758)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$3(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$1(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:153)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:122)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:93)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:824)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1621)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:827)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:683)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2920)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2914)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2914)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1334)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1334)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1334)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3123)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3111)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: org.apache.spark.api.python.PythonException: 'ValueError: invalid literal for int() with base 10: ''', from <command-3048127638877849>, line 17. Full traceback below:\nTraceback (most recent call last):\n  File \"<command-3048127638877849>\", line 17, in parse_clf_time\nValueError: invalid literal for int() with base 10: ''\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:689)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:642)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:758)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$3(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$1(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:153)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:122)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:93)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:824)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1621)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:827)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:683)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\n  warnings.warn(msg)\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["/databricks/spark/python/pyspark/sql/pandas/conversion.py:161: UserWarning: toPandas attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true, but has reached the error below and can not continue. Note that 'spark.sql.execution.arrow.pyspark.fallback.enabled' does not have an effect on failures in the middle of computation.\n  An error occurred while calling o3153.getResult.\n: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:428)\n\tat org.apache.spark.security.SocketAuthServer.getResult(SocketAuthServer.scala:107)\n\tat org.apache.spark.security.SocketAuthServer.getResult(SocketAuthServer.scala:103)\n\tat sun.reflect.GeneratedMethodAccessor622.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 183.0 failed 1 times, most recent failure: Lost task 0.0 in stage 183.0 (TID 813) (ip-10-172-192-231.us-west-2.compute.internal executor driver): org.apache.spark.api.python.PythonException: 'ValueError: invalid literal for int() with base 10: ''', from <command-3048127638877849>, line 17. Full traceback below:\nTraceback (most recent call last):\n  File \"<command-3048127638877849>\", line 17, in parse_clf_time\nValueError: invalid literal for int() with base 10: ''\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:689)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:642)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:758)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$3(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$1(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:153)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:122)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:93)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:824)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1621)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:827)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:683)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2920)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2914)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2914)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1334)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1334)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1334)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3123)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3111)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: org.apache.spark.api.python.PythonException: 'ValueError: invalid literal for int() with base 10: ''', from <command-3048127638877849>, line 17. Full traceback below:\nTraceback (most recent call last):\n  File \"<command-3048127638877849>\", line 17, in parse_clf_time\nValueError: invalid literal for int() with base 10: ''\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:689)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:642)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:758)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$3(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$1(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:153)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:122)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:93)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:824)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1621)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:827)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:683)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\n  warnings.warn(msg)\n"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n\u001B[0;32m<command-3048127638877883>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m                      \u001B[0;34m.\u001B[0m\u001B[0mcount\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m                      .sort(\"day\"))\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mdaily_hosts_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdaily_hosts_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoPandas\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0mdaily_hosts_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/databricks/utils/instrumentation.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m             \u001B[0mstart_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 42\u001B[0;31m             \u001B[0mreturn_val\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     43\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     44\u001B[0m             \u001B[0mduration\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart_time\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;36m1000\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/pandas/conversion.py\u001B[0m in \u001B[0;36mtoPandas\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    115\u001B[0m                     \u001B[0mtmp_column_names\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'col_{}'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m                     \u001B[0mself_destruct\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql_ctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_conf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marrowPySparkSelfDestructEnabled\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m                     batches = self.toDF(*tmp_column_names)._collect_as_arrow(\n\u001B[0m\u001B[1;32m    118\u001B[0m                         split_batches=self_destruct)\n\u001B[1;32m    119\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatches\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/pandas/conversion.py\u001B[0m in \u001B[0;36m_collect_as_arrow\u001B[0;34m(self, split_batches)\u001B[0m\n\u001B[1;32m    294\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    295\u001B[0m             \u001B[0;31m# Join serving thread and raise any exceptions from collectAsArrowToPython\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 296\u001B[0;31m             \u001B[0mjsocket_auth_server\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetResult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    297\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    298\u001B[0m         \u001B[0;31m# Separate RecordBatches from batch order indices in results\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1303\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1304\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    115\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOUTPUT_CONVERTER\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    325\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 326\u001B[0;31m                 raise Py4JJavaError(\n\u001B[0m\u001B[1;32m    327\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n\n\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o3153.getResult.\n: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:428)\n\tat org.apache.spark.security.SocketAuthServer.getResult(SocketAuthServer.scala:107)\n\tat org.apache.spark.security.SocketAuthServer.getResult(SocketAuthServer.scala:103)\n\tat sun.reflect.GeneratedMethodAccessor622.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 183.0 failed 1 times, most recent failure: Lost task 0.0 in stage 183.0 (TID 813) (ip-10-172-192-231.us-west-2.compute.internal executor driver): org.apache.spark.api.python.PythonException: 'ValueError: invalid literal for int() with base 10: ''', from <command-3048127638877849>, line 17. Full traceback below:\nTraceback (most recent call last):\n  File \"<command-3048127638877849>\", line 17, in parse_clf_time\nValueError: invalid literal for int() with base 10: ''\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:689)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:642)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:758)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$3(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$1(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:153)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:122)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:93)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:824)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1621)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:827)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:683)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2920)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2914)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2914)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1334)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1334)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1334)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3123)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3111)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: org.apache.spark.api.python.PythonException: 'ValueError: invalid literal for int() with base 10: ''', from <command-3048127638877849>, line 17. Full traceback below:\nTraceback (most recent call last):\n  File \"<command-3048127638877849>\", line 17, in parse_clf_time\nValueError: invalid literal for int() with base 10: ''\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:689)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:642)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:758)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$3(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$1(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:153)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:122)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:93)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:824)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1621)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:827)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:683)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n","errorSummary":"org.apache.spark.SparkException: Exception thrown in awaitResult: ","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n\u001B[0;32m<command-3048127638877883>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m                      \u001B[0;34m.\u001B[0m\u001B[0mcount\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m                      .sort(\"day\"))\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mdaily_hosts_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdaily_hosts_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoPandas\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0mdaily_hosts_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/databricks/utils/instrumentation.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m             \u001B[0mstart_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 42\u001B[0;31m             \u001B[0mreturn_val\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     43\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     44\u001B[0m             \u001B[0mduration\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart_time\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;36m1000\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/pandas/conversion.py\u001B[0m in \u001B[0;36mtoPandas\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    115\u001B[0m                     \u001B[0mtmp_column_names\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'col_{}'\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m                     \u001B[0mself_destruct\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msql_ctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_conf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marrowPySparkSelfDestructEnabled\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m                     batches = self.toDF(*tmp_column_names)._collect_as_arrow(\n\u001B[0m\u001B[1;32m    118\u001B[0m                         split_batches=self_destruct)\n\u001B[1;32m    119\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatches\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/pandas/conversion.py\u001B[0m in \u001B[0;36m_collect_as_arrow\u001B[0;34m(self, split_batches)\u001B[0m\n\u001B[1;32m    294\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    295\u001B[0m             \u001B[0;31m# Join serving thread and raise any exceptions from collectAsArrowToPython\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 296\u001B[0;31m             \u001B[0mjsocket_auth_server\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetResult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    297\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    298\u001B[0m         \u001B[0;31m# Separate RecordBatches from batch order indices in results\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1303\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1304\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    115\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOUTPUT_CONVERTER\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    325\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 326\u001B[0;31m                 raise Py4JJavaError(\n\u001B[0m\u001B[1;32m    327\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n\n\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o3153.getResult.\n: org.apache.spark.SparkException: Exception thrown in awaitResult: \n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:428)\n\tat org.apache.spark.security.SocketAuthServer.getResult(SocketAuthServer.scala:107)\n\tat org.apache.spark.security.SocketAuthServer.getResult(SocketAuthServer.scala:103)\n\tat sun.reflect.GeneratedMethodAccessor622.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 183.0 failed 1 times, most recent failure: Lost task 0.0 in stage 183.0 (TID 813) (ip-10-172-192-231.us-west-2.compute.internal executor driver): org.apache.spark.api.python.PythonException: 'ValueError: invalid literal for int() with base 10: ''', from <command-3048127638877849>, line 17. Full traceback below:\nTraceback (most recent call last):\n  File \"<command-3048127638877849>\", line 17, in parse_clf_time\nValueError: invalid literal for int() with base 10: ''\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:689)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:642)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:758)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$3(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$1(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:153)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:122)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:93)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:824)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1621)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:827)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:683)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2920)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2914)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2914)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1334)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1334)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1334)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3123)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3111)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: org.apache.spark.api.python.PythonException: 'ValueError: invalid literal for int() with base 10: ''', from <command-3048127638877849>, line 17. Full traceback below:\nTraceback (most recent call last):\n  File \"<command-3048127638877849>\", line 17, in parse_clf_time\nValueError: invalid literal for int() with base 10: ''\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:689)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:642)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.agg_doAggregateWithKeys_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:758)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$3(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$1(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:153)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:122)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:93)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:824)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1621)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:827)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:683)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["host_day_distinct_df.take(10)\n#distinct_df = daily_hosts_df.select(daily_hosts_df['day']).distinct()\n#distinct_df.take(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"46f516b2-ccb4-4f2d-9c23-35cc120ecf94"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[162]: [Row(host='129.94.144.152', day=1),\n Row(host='d104.aa.net', day=1),\n Row(host='199.72.81.55', day=1),\n Row(host='205.189.154.54', day=1),\n Row(host='199.120.110.21', day=1),\n Row(host='205.212.115.106', day=1),\n Row(host='unicomp6.unicomp.net', day=1),\n Row(host='net-1-141.eden.com', day=1),\n Row(host='burger.letters.com', day=1),\n Row(host='ppptky391.asahi-net.or.jp', day=1)]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[162]: [Row(host='129.94.144.152', day=1),\n Row(host='d104.aa.net', day=1),\n Row(host='199.72.81.55', day=1),\n Row(host='205.189.154.54', day=1),\n Row(host='199.120.110.21', day=1),\n Row(host='205.212.115.106', day=1),\n Row(host='unicomp6.unicomp.net', day=1),\n Row(host='net-1-141.eden.com', day=1),\n Row(host='burger.letters.com', day=1),\n Row(host='ppptky391.asahi-net.or.jp', day=1)]"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ffdc53e9-f110-42ca-acd5-7b2229ede33a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"26538fb0-3d3f-4b88-a18d-e8ae35258be2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8d14066c-9ae0-4c8a-ab0a-688f730e08d1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d475f371-ec0f-4694-9e9a-f96f566fddc0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d10997a6-cc9d-40d3-85a3-f0851f990e8b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["daily_hosts_df.plot(x='day', y='count', kind='line')"],"metadata":{"colab":{},"colab_type":"code","id":"PUdqNQHiXvDz","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"85effc11-f95c-4dcc-891b-716b75f3d30d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n\u001B[0;32m<command-3048127638877884>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdaily_hosts_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'day'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'count'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkind\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'line'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py\u001B[0m in \u001B[0;36m__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1798\u001B[0m         \"\"\"\n\u001B[1;32m   1799\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1800\u001B[0;31m             raise AttributeError(\n\u001B[0m\u001B[1;32m   1801\u001B[0m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001B[1;32m   1802\u001B[0m         \u001B[0mjc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'plot'","errorSummary":"<span class='ansi-red-fg'>AttributeError</span>: 'DataFrame' object has no attribute 'plot'","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n\u001B[0;32m<command-3048127638877884>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdaily_hosts_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'day'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'count'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkind\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'line'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py\u001B[0m in \u001B[0;36m__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1798\u001B[0m         \"\"\"\n\u001B[1;32m   1799\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1800\u001B[0;31m             raise AttributeError(\n\u001B[0m\u001B[1;32m   1801\u001B[0m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001B[1;32m   1802\u001B[0m         \u001B[0mjc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'plot'"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"df3db02f-2e42-463f-ae83-ea9d7ed1b677"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Your Turn: Q9: Counting 404 Response Codes\n\nCreate a DataFrame containing only log records with a 404 status code (Not Found). \n\nMake sure you `cache()` the `not_found_df` dataframe as we will use it in the rest of the exercises here.\n\n__How many 404 records are in the log?__"],"metadata":{"colab_type":"text","id":"O5M-HoWHXvD1","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"82af59d5-84bd-4ee0-9530-7676a4da3f53"}}},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\n\nnot_found_df = logs_df.filter(logs_df['status']==404).cache()\nprint(('Total 404 responses: {}').format(not_found_df.count()))"],"metadata":{"colab_type":"code","id":"XovkxrduXvD2","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"76f1bed8-766d-41f3-831e-37b18b4a733d"},"colab":{},"outputId":"662c54ce-9fd3-4d97-dbf5-30a1a77b90f9"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Total 404 responses: 20899\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Total 404 responses: 20899\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Your Turn: Q10: Listing the Top Twenty 404 Response Code Endpoints\n\nUsing the DataFrame containing only log records with a 404 response code that you cached in Q9, print out a list of the top twenty endpoints that generate the most 404 errors.\n\n*Remember, top endpoints should be in sorted order*"],"metadata":{"colab_type":"text","id":"wdwYDLCnXvD5","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"120b82b7-c164-46ad-9a34-9a9150f830c8"}}},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\n\nhosts_404_count_df = (not_found_df.groupby('endpoint').count().orderBy('count', ascending=False).limit(20))\n\nhosts_404_count_df.show(truncate=False)"],"metadata":{"colab_type":"code","id":"Gv3egQAEXvD5","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c63d4cf1-ffb6-4ba8-8d3f-4d1ae506d719"},"colab":{},"outputId":"6725f87c-1cd4-4387-f61f-9c7cd58f1f93"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-----------------------------------------------------------------+-----+\n|endpoint                                                         |count|\n+-----------------------------------------------------------------+-----+\n|/pub/winvn/readme.txt                                            |2004 |\n|/pub/winvn/release.txt                                           |1732 |\n|/shuttle/missions/STS-69/mission-STS-69.html                     |683  |\n|/shuttle/missions/sts-68/ksc-upclose.gif                         |428  |\n|/history/apollo/a-001/a-001-patch-small.gif                      |384  |\n|/history/apollo/sa-1/sa-1-patch-small.gif                        |383  |\n|/://spacelink.msfc.nasa.gov                                      |381  |\n|/images/crawlerway-logo.gif                                      |374  |\n|/elv/DELTA/uncons.htm                                            |372  |\n|/history/apollo/pad-abort-test-1/pad-abort-test-1-patch-small.gif|359  |\n|/images/nasa-logo.gif                                            |319  |\n|/shuttle/resources/orbiters/atlantis.gif                         |314  |\n|/history/apollo/apollo-13.html                                   |304  |\n|/shuttle/resources/orbiters/discovery.gif                        |263  |\n|/shuttle/missions/sts-71/images/KSC-95EC-0916.txt                |190  |\n|/shuttle/resources/orbiters/challenger.gif                       |170  |\n|/shuttle/missions/technology/sts-newsref/stsref-toc.html         |158  |\n|/history/apollo/images/little-joe.jpg                            |150  |\n|/images/lf-logo.gif                                              |143  |\n|/history/apollo/publications/sp-350/sp-350.txt~                  |140  |\n+-----------------------------------------------------------------+-----+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-----------------------------------------------------------------+-----+\n|endpoint                                                         |count|\n+-----------------------------------------------------------------+-----+\n|/pub/winvn/readme.txt                                            |2004 |\n|/pub/winvn/release.txt                                           |1732 |\n|/shuttle/missions/STS-69/mission-STS-69.html                     |683  |\n|/shuttle/missions/sts-68/ksc-upclose.gif                         |428  |\n|/history/apollo/a-001/a-001-patch-small.gif                      |384  |\n|/history/apollo/sa-1/sa-1-patch-small.gif                        |383  |\n|/://spacelink.msfc.nasa.gov                                      |381  |\n|/images/crawlerway-logo.gif                                      |374  |\n|/elv/DELTA/uncons.htm                                            |372  |\n|/history/apollo/pad-abort-test-1/pad-abort-test-1-patch-small.gif|359  |\n|/images/nasa-logo.gif                                            |319  |\n|/shuttle/resources/orbiters/atlantis.gif                         |314  |\n|/history/apollo/apollo-13.html                                   |304  |\n|/shuttle/resources/orbiters/discovery.gif                        |263  |\n|/shuttle/missions/sts-71/images/KSC-95EC-0916.txt                |190  |\n|/shuttle/resources/orbiters/challenger.gif                       |170  |\n|/shuttle/missions/technology/sts-newsref/stsref-toc.html         |158  |\n|/history/apollo/images/little-joe.jpg                            |150  |\n|/images/lf-logo.gif                                              |143  |\n|/history/apollo/publications/sp-350/sp-350.txt~                  |140  |\n+-----------------------------------------------------------------+-----+\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Your Turn: Q11: Visualizing 404 Errors per Day\n\nLet's explore the 404 records temporally now. Similar to the example showing the number of unique daily hosts, break down the 404 requests by day and get the daily counts sorted by day in `errors_by_date_sorted_df`.\n\n- Display the results as a pandas dataframe \n- Also visualize the same dataframe then as a line chart"],"metadata":{"colab_type":"text","id":"UpQl8xaPXvD8","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2bf3338d-5ec8-4bd6-847b-b5e7f414b862"}}},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\nfrom pyspark.sql.dataframe import DataFrame\nfrom pyspark.sql.types import StringType, DataType\nfrom pyspark.sql.udf import UserDefinedFunction, _create_udf\nimport pyspark.sql.functions as f\n\nerrors_by_date_sorted_df = not_found_df.select(f.dayofmonth(not_found_df['time']).alias('day')).groupBy('day').count().sort('day')\n\nerrors_by_date_sorted_df = errors_by_date_sorted_df.toPandas()\nerrors_by_date_sorted_df.T"],"metadata":{"colab_type":"code","id":"69N8tHpzXvD9","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"145945a0-bb0b-42df-a2a8-eb82bde39114"},"colab":{},"outputId":"1746aabb-b068-43c0-bbe6-580c3fce7639"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n      <th>30</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>day</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>5</td>\n      <td>6</td>\n      <td>7</td>\n      <td>8</td>\n      <td>9</td>\n      <td>10</td>\n      <td>11</td>\n      <td>12</td>\n      <td>13</td>\n      <td>14</td>\n      <td>15</td>\n      <td>16</td>\n      <td>17</td>\n      <td>18</td>\n      <td>19</td>\n      <td>20</td>\n      <td>21</td>\n      <td>22</td>\n      <td>23</td>\n      <td>24</td>\n      <td>25</td>\n      <td>26</td>\n      <td>27</td>\n      <td>28</td>\n      <td>29</td>\n      <td>30</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>count</th>\n      <td>559</td>\n      <td>291</td>\n      <td>778</td>\n      <td>705</td>\n      <td>733</td>\n      <td>1013</td>\n      <td>1107</td>\n      <td>691</td>\n      <td>627</td>\n      <td>713</td>\n      <td>734</td>\n      <td>667</td>\n      <td>748</td>\n      <td>700</td>\n      <td>581</td>\n      <td>516</td>\n      <td>677</td>\n      <td>721</td>\n      <td>848</td>\n      <td>740</td>\n      <td>639</td>\n      <td>480</td>\n      <td>578</td>\n      <td>748</td>\n      <td>876</td>\n      <td>702</td>\n      <td>706</td>\n      <td>504</td>\n      <td>420</td>\n      <td>571</td>\n      <td>526</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n      <th>30</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>day</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>5</td>\n      <td>6</td>\n      <td>7</td>\n      <td>8</td>\n      <td>9</td>\n      <td>10</td>\n      <td>11</td>\n      <td>12</td>\n      <td>13</td>\n      <td>14</td>\n      <td>15</td>\n      <td>16</td>\n      <td>17</td>\n      <td>18</td>\n      <td>19</td>\n      <td>20</td>\n      <td>21</td>\n      <td>22</td>\n      <td>23</td>\n      <td>24</td>\n      <td>25</td>\n      <td>26</td>\n      <td>27</td>\n      <td>28</td>\n      <td>29</td>\n      <td>30</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>count</th>\n      <td>559</td>\n      <td>291</td>\n      <td>778</td>\n      <td>705</td>\n      <td>733</td>\n      <td>1013</td>\n      <td>1107</td>\n      <td>691</td>\n      <td>627</td>\n      <td>713</td>\n      <td>734</td>\n      <td>667</td>\n      <td>748</td>\n      <td>700</td>\n      <td>581</td>\n      <td>516</td>\n      <td>677</td>\n      <td>721</td>\n      <td>848</td>\n      <td>740</td>\n      <td>639</td>\n      <td>480</td>\n      <td>578</td>\n      <td>748</td>\n      <td>876</td>\n      <td>702</td>\n      <td>706</td>\n      <td>504</td>\n      <td>420</td>\n      <td>571</td>\n      <td>526</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["errors_by_date_sorted_df.plot.line(x='day', y='count')"],"metadata":{"colab":{},"colab_type":"code","id":"y-pFX8dJXvD_","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"25ec8ce6-818c-4b8d-a2bb-d13bd03cf179"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[144]: <AxesSubplot:xlabel='day'>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[144]: <AxesSubplot:xlabel='day'>"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAX0AAAEGCAYAAACJnEVTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABA5ElEQVR4nO3dd3ic5ZXw/+/RqFm9y5YlW7Js3Bu4O1QHYkpikiUQQggQAtlNsqS8eRM25SXJJvmx6Qu7y4aEYgiEEAjBISQUYzAuuIF7lSXZlpukUbGKpZFm7t8f84wsyyqjKZp2PtflSzPPPDNzDxJHt85z3+eIMQallFKxIS7UA1BKKTVyNOgrpVQM0aCvlFIxRIO+UkrFEA36SikVQ+JDPYDB5OXlmdLS0lAPQymlIsq2bdvqjTH5/T0W1kG/tLSUrVu3hnoYSikVUUTkyECPaXpHKaViiAZ9pZSKIRr0lVIqhoR1Tl8ppYbS1dVFTU0NHR0doR7KiEtOTqa4uJiEhASvn6NBXykV0WpqakhPT6e0tBQRCfVwRowxBrvdTk1NDWVlZV4/T9M7SqmI1tHRQW5ubkwFfAARITc3d9h/4WjQV0pFvFgL+B6+fO4hg76IPC4itSKyu9exT4rIHhFxici8Puf/m4hUiMgBEflIr+PLrWMVInL/sEeqBtXldPGHzUfp6HKGeihKqTDmzUz/SWB5n2O7gU8Aa3sfFJFpwKeA6dZz/kdEbCJiA/4buBaYBtxqnasC5E9ba/i3P+/i7QN1oR6KUirAfv3rX9Pe3h6Q1xoy6Btj1gINfY7tM8Yc6Of0FcBzxphOY0wVUAEssP5VGGMqjTEO4DnrXBUALpfhsXWVAJw+E3srGJSKdiMa9IdpLHCs1/0a69hAxy8gIveKyFYR2VpXp7NWb7xzsI7DdW2ABn2lQuWpp55i1qxZzJ49m9tvv53q6mquuuoqZs2axbJlyzh69CgAd955Jy+88ELP89LS0gB4++23ueKKK7jpppuYMmUKt912G8YYHnroIU6cOMGVV17JlVde6fc4w27JpjHmUeBRgHnz5mkvRy/8bl0lozOScRpDbUtnqIejVMj84K972HviTEBfc1pRBg98dPqg5+zZs4cf/ehHbNiwgby8PBoaGrjjjjt6/j3++OPcd999/OUvfxn0dT744AP27NlDUVERS5cuZf369dx333388pe/ZM2aNeTl5fn9eQI90z8OlPS6X2wdG+i48tPeE2dYX2HnjiWlFGWN0pm+UiHw1ltv8clPfrInKOfk5LBx40Y+/elPA3D77bezbt26IV9nwYIFFBcXExcXx5w5c6iurg74WAM9018FPCsivwSKgEnAZkCASSJShjvYfwr4dIDfOyY9tq6KUQk2Pr1gHB8cbeSIPTB5P6Ui0VAz8nAQHx+Py+UCwOVy4XA4eh5LSkrquW2z2eju7g74+3uzZPMPwEZgsojUiMjdIvJxEakBFgN/E5HXAIwxe4Dngb3AP4AvGWOcxphu4MvAa8A+4HnrXOWH2jMdrNpxnJvnFZOZkkBBRhKnW3Smr9RIu+qqq/jTn/6E3W4HoKGhgSVLlvDcc88B8Mwzz3DppZcC7pLx27ZtA2DVqlV0dXUN+frp6em0tLQEZKxDzvSNMbcO8NBLA5z/Y+DH/Rx/FXh1WKNTg3pq4xG6XYbPfci9BbswPZmm9i46upwkJ9hCPDqlYsf06dP5zne+w+WXX47NZmPu3Lk8/PDD3HXXXfzsZz8jPz+fJ554AoB77rmHFStWMHv2bJYvX05qauqQr3/vvfeyfPlyioqKWLNmjV9jFWPC91rpvHnzjDZR6d9Zh5PFD65mYVkOv7ndvT/u+S3H+OaLO3n3m1dSkpMS4hEqNTL27dvH1KlTQz2MkOnv84vINmPMvP7O1zIMEerF92toau/i85dO6DlWkOHOB9ZqikcpNQAN+hHI5TI8vq6K2cWZzBuf3XO8ID0ZgNNndNmmUqp/GvQj0JoDtVTWt3H3pRPOK7hUaM30ddmmijXhnKYOJl8+twb9CPS7d6soykzm2hmjzzuenZJIgk10g5aKKcnJydjt9pgL/J56+snJycN6XtjtyFWD2328mY2Vdr593RQSbOf/zo6LEwrSk3Wmr2JKcXExNTU1xGLZFk/nrOHQoB9hHl9XRWqijVvmj+v38YKMJGo1p69iSEJCwrA6R8U6Te9EkFPNHazacYKb55eQOar/npgF6Uk601dKDUiDfgR5amM1LmO4a8nAs5rCjGTN6SulBqRBP0K0O7p5ZtNRPjJ9NONyB954VZiRTPPZLu2gpZTqlwb9CPHithqaz3bx+UsHz10WpFsbtDSvr5Tqhwb9CODujFXFnJIsLh6XPei5BRnWBi3dlauU6ocG/Qiwen8t1fZ2Pn9p2XmbsfqjG7SUUoPRoB8BfvduJWOzRrF8+ughzy20SjFoekcp1R8N+mFu9/FmNlU1cNfSUuJtQ3+7slISSLTFaXpHKdUvb5qoPC4itSKyu9exHBF5Q0QOWV+zreMiIg+JSIWI7BSRi3s95w7r/EMickdwPk70ea/S3ZRhxZx++8hfQER0g5ZSakDezPSfBJb3OXY/sNoYMwlYbd0HuBZ3i8RJwL3AI+D+JQE8ACwEFgAPeH5RqMFV1beROSqBvLREr5+jG7SUUgMZMugbY9YCDX0OrwBWWrdXAjf2Ov6UcXsPyBKRMcBHgDeMMQ3GmEbgDS78RaL6UVXfRlle6pAXcHvTDVpKqYH4mtMvNMactG6fAgqt22OBY73Oq7GODXT8AiJyr4hsFZGtsVhAqa+q+jYm5A/dTq23wgwtuqaU6p/fF3KNu55pwGqaGmMeNcbMM8bMy8/PD9TLRqR2RzcnmzuYkDe8oF+QkURLRzftju4gjUwpFal8DfqnrbQN1tda6/hxoKTXecXWsYGOq0FU1bcBUJaXNqznFeiyTaXUAHwN+qsAzwqcO4CXex3/rLWKZxHQbKWBXgOuEZFs6wLuNdYxNQhP0B9+esfTK1eDvlLqfEPW0xeRPwBXAHkiUoN7Fc6DwPMicjdwBLjZOv1V4DqgAmgH7gIwxjSIyL8DW6zzfmiM6XtxWPVRVecO+qW5w8/pg+7KVUpdaMigb4y5dYCHlvVzrgG+NMDrPA48PqzRxbjK+jaKMpMZlWgb1vMK0zXoK6X6pztyw1hlfRtlw0ztAGSMiicxPk7TO0qpC2jQD1PGGKrqWpkwzIu44N6VW5iRRK3O9JVSfWjQD1P2NgdnOropG+ZyTY/C9GRO6+odpVQfGvTDVM9yTR/SO2Bt0NKia0qpPjTohynPyp1yH9I7gBZdU0r1S4N+mKqsbyPBJozNHuXT8wvSk2nt7KatU3flKqXO0aAfpirrWhmfm4otzvtCa73pBi2lVH806IcpT3VNX+kGLaVUfzTohyGny3DE3j7s8gu9aa9cpVR/NOiHoeONZ3E4XcOurtlbvhZdU0r1Q4N+GKqsbwWGX12zt4zkeJIT4qjVZZtKqV406IchX6tr9ubelasbtJRS59OgH4aq6ttIT44nN9X7vrj9ce/K1Zm+UuocDfphqLKujQnD7Ivbn4KMJF2yqZQ6jwb9MOTvck2PgvRkLbqmlDqPX0FfRL4iIrtFZI+IfNU6liMib4jIIetrtnVcROQhEakQkZ0icnEAxh91OrqcHG86y4R83y/iehRmJNHmcNKqu3KVUhafg76IzADuARYAs4EbRGQicD+w2hgzCVht3Qe4Fphk/bsXeMSPcUetarunL67/M33doKWU6sufmf5UYJMxpt0Y0w28A3wCWAGstM5ZCdxo3V4BPGXc3gOyPM3V1TmVdYEL+gW6QUsp1Yc/QX83cKmI5IpICu7euCVAodUMHeAUUGjdHgsc6/X8GuvYeUTkXhHZKiJb6+rq/BheZOopqRygnD7oBi2l1Dk+B31jzD7gP4DXgX8A2wFnn3MMYIb5uo8aY+YZY+bl5+f7OryIVVnXxuiMZFKThmxfPKRzRdd0pq+UcvPrQq4x5jFjzCXGmMuARuAgcNqTtrG+1lqnH8f9l4BHsXVM9VJZ3xqQWT5AWlI8KYk23aCllOrh7+qdAuvrONz5/GeBVcAd1il3AC9bt1cBn7VW8SwCmnulgZSlysdm6P05tytXZ/pKKTd/cwgvikgu0AV8yRjTJCIPAs+LyN3AEeBm69xXcef9K4B24C4/3zvqNLY5aGrv8qvQWl8F6dpBSyl1jl9B3xhzaT/H7MCyfo4b4Ev+vF+0qwxAzZ2+CjKS2VXTFLDXU2qk7T91hqq6Nq6dqYv9AkF35IaRyjr/q2v2VZiexOkznbh/5yoVeX70yj6+8tx2OrqcQ5+shqRBP4xU1bcRHyeU+NgXtz+FGcmc7XLSortyVQRqaHOwsdKOw+liZ01zqIcTFTToh5Gq+jbG5aYQbwvct8WzQUtr8KhI9MbeUzhd7r9SN1fZQzya6KBBP4x4qmsGkm7QUpHs77tPUZIziimj09lU1RDq4UQFDfphwuUyVNkDU12zt55eubpBS0WY5vYu1lfUc+2MMSwoy+H9I410O12hHlbE06AfJk40n8XR7QpIdc3eCnqKrulMX0WWN/edpstpuHbGaOaX5tDmcLL35JlQDyviadAPE4GsudNbWlI8aUnxukErSmw70sg3X9jRk+eOZn/ffZKizGTmlGSxoCwHgM2a4vGbBv0w4amuGeicPlgbtLSDVlT47dpKnt9aw9qD0V2MsKWji7WH6lk+Y0zPzvLS3BQN+gGgQT9MVNW3kZYUT356UsBfuyAjSVfvRIG2zm7WHHCXsvrjlmNDnB3Z3tpfi6PbxbUzR/ccm1+aw5bqBlwx8FdOMGnQDxOVVotEf/vi9sddf0dn+pFuzYFaOrtdzB2XxZv7TlPfGr3f07/vOkVBehKXjMvuObagLIfG9i4qrE2Myjca9MNEZV3gqmv25Sm6prtyI9vfd50iLy2JBz8xi26X4c/v14R6SEHR7ujm7YO1LJ8xmri4c5MgzesHhgb9MODpixusoF+QnkRnt4szZ3VXbqQ663Dy1v5als8oZPLodC4Zn80ftxyLyl/kbx+oo6PLxbUzzq+1My4nhcKMJA36ftKgHwaONrRjTGALrfXmWbapzVQi19sHajnb5eQ6KxDeMq+Ew3VtvH+0McQjC7xXd50kNzWxZ2bvISIsKMtlc1VDVP6yGyka9MPAuZU7gV2j71GY7umVG7054Gj3tz6B8PpZY0hNtPHc5ui6oNvR5f6L5prpo7HFXXh9a0FpNqfOdFDTeDYEo4sOGvTDQGW9+8JUaV5KUF6/sGeDls70I1HvQOipy5SaFM9HZxfxt10naY2iYnrvHKyj3eHkul6rdnpbUJYLoCUZ/OBv56yvicgeEdktIn8QkWQRKRORTSJSISJ/FJFE69wk636F9XhpQD5BFKiqa6MgPYn05ISgvH6BlmKIaJ5AeH2fevI3zy+h3eHklR0nQjSywPvH7lNkpSSwaEJuv49PKkgjc1QCWzTo+8znoC8iY4H7gHnGmBmADfgU7mbpvzLGTMTdN/du6yl3A43W8V9Z5ymsFolBuogLkJIYT3pSvBZdi1Cv7jpJdkoCiyacn+OeW5LFpII0nouSNfud3U7e3Huaa6YVkjBApdm4OGF+aQ6bqzXo+8rf9E48MEpE4oEU4CRwFfCC9fhK4Ebr9grrPtbjyyQYi9IjUFV9W9Au4noUZCTphdwI1NHlZPW+Wj7SK7XjISLcMr+E7ceaOHi6JUQjDJz1FfW0dHZfsGqnr4VlOVTVt+nPs498DvrGmOPAz4GjuIN9M7ANaDLGeJKMNcBY6/ZY4Jj13G7r/P7/hoshze1d2NscQZ3pg27QilTvHqqntbN7wFaBH587lgSbRMUO3Vd3nSI9OZ4lEwcPC/Oti9lbqqJv5dJI8Ce9k4179l4GFAGpwHJ/ByQi94rIVhHZWlcX3fVF4NxF3GCt3PHwbNBSkeXvu06SOSqBJeX9B8LctCSunlbISx8cp7M7ctsJdjldvLH3NFdPLSQp3jboudOLMkhJtGlTFR/5k975MFBljKkzxnQBfwaWAllWugegGDhu3T4OlABYj2cCF3zXjDGPGmPmGWPm5efn+zG8yNBTXXNE0jvaKzeSdHY7eWOIHDfAzfNKaGhz8Obe2hEcXWBtPGyn+WyXV83PE2xxXDwuW1fw+MifoH8UWCQiKVZufhmwF1gD3GSdcwfwsnV7lXUf6/G3jEYgKuvasMUJJdnBWa7pUZCejKPbRfPZrqC+jwocT477uiEC4aWT8inKTOaPWyM3xfP33SdJTbRx6aQ8r85fUJbDgdMtNLfrz/Nw+ZPT34T7guz7wC7rtR4FvgV8XUQqcOfsH7Oe8hiQax3/OnC/H+OOGlX1bYzLSSExPrhbJno6aGleP2J4ctxLJw4eCG1xwk3zSnj3UB3HmyJv01K308Xre05z1dRCkhMGT+14LCjLwRjYekRn+8PlV6QxxjxgjJlijJlhjLndGNNpjKk0xiwwxkw0xnzSGNNpndth3Z9oPV4ZmI8wMv7n7Qp+927gh1wZ5OWaHrpBK7I4ul28vucUV08r9GpC8MlLigH4UwTO9jdXN2Bvc3DdjP43ZPVnTkkWCTbROjw+0B25XnphWw3/39/3cyiAS+NcLkP1SAX9dA36kWTD4XrOdHRfsCFrICU5KSwtz+NPW2sirt7833edYlSCjSsmF3j9nOQEG7OLs3S9vg806HvJ3urA6TL86G/7Avaap850cLbLOSJB37MrVztoRYZXd50kPSmeD3mZ4wb3Dt3jTWdZf7g+iCMLLJfL8I89p7hySj6jEr1L7XjML8thV00z7Y7oKUMxEjToe8FzAbQoM5l3DtaxZn9gVkl4Vu4Ee2MWuGdGGcnx2kErAnQ5Xby+9zQfnjb08sXerplWSFZKQkTt0N12tJG6lk6WD7Ehqz8LynLodhm2H20K/MCimAZ9LzS2OwC497IJTMhL5d//tpcup8vv162sD251zb50g1Zk2HjYTlN7F9cOI8cN7l/sN84Zyxt7TtPY5gjS6ALr1V0nSYyP46op3qd2PC4Zn02caPG14dKg7wVPW7rRmaP4zvVTqaxr46mNR/x+3cq6VlISbT0ra4KtMCNZi65FAM/yxcsuGv4+lVvml+Bwunjpg+NDnxxiLpfhH7tPcflF+aQlxQ/9hD4ykhOYOiZDL+YOkwZ9L9hb3bOmvLRErppSwKWT8vjPNw/S4OdsqiqIfXH7U5CepEXXwly308Vre06zbBjLF3ubOiaDWcWZEdFVa3tNEyebOwYso+yNBWU5fHCsEUe3/395xwoN+l6wt7kDZW5aEiLC/7thGm0OJ79844Bfrxvs6pp9FWQkU9sSPb1ym8928fTGajq6Irf8QF+bqhpoaHP4FQhvmV/CgdMt7KhpDuDIAu8fu0+RYBOumlLo82ssKM2ho8vFruPh/VnDiQZ9L3hm+rlpiQBMKkznMwvH8eymo+w/dcan13R0uzjW0M6EEQz6hRlJdDkNjVGyi/Hnrx3gey/v4Rt/2hFxyxQH8uquk6QkDm/5Yl8fnV1EckJc2BdhW7O/lkUTcskc5XsfifnaLH3YNOh7ob7VQaItjvReecevfvgi0pMT+PdX9vo0cz7a0IbLBL/mTm/RtEHrWEM7z205SlleKq/sPMl/vLY/1EPym9NleG3PKa6cUuBTascjIzmB62aO4a87ToTtckZ7ayeHaltZPEAhOW/lpSVRnp/KFl2v7zUN+l6wt3aSm5Z4Xu49OzWRr314Eusr7Lyx9/SwXzPYfXH7UxjitfqObhdtAWrt99DqQ4gIz96zkM8sGsdv3qnk6ff8v7geSpurGqhvdXi9IWswty4YR2tnN6u2h2dXLc/MfGGZ/9XVF5TlsKW6AWeU/LUXbBr0vWBvc/Skdnq7bdF4Jhak8eNX9w2rrO1Zh5OXrRZ3pSOZ0w/RrtyOLidPrK/iQ//xFtf8ai0tHf6llw7XtfLi+zV8ZuF4xmSO4vsfnc5VUwp44OXdrN43/F/A4eLVXSdJTojjisn+V5edNz6byYXpPLXxSFhew9lU1cCoBBuzijP9fq0FZTm0dHT7nGqNNRr0vWBv7SQ39cJllQm2OL57/VSO2NtZuaHaq9faWt3AdQ+9y992nuSfLy/3K585XPnp1kx/hIJ+R5eTJ9dXcdlP1/CDv+5lbPYoTjSf5RevH/TrdX/95iGS4m188cpyAOJtcTx861ymFWXw5Wc/YFeYX8Dsj9OzM3VyASmJw1++2JeIcPvi8ew9eYYPjjX5P8AAe6/SziXjswctGe2t+aWepiqa4vGGBn0v1Lf2P9MHuGJyAVdOzufh1RU96/n7c9bh5N9f2csnf7ORLqeLZ+9ZyP3XTgnWkPuVnGAjKyUh6Bu0OrqcrNxQzeU/W8P3/7qX0txUnr1nIS99cSm3LxrPyo3V7PAxEO07eYa/7jjBXUtLyUs794s4NSmex++cT05qIp9buYVjDe0B+jQjY9sR987UocooD8eNc8eSlhTP7wOwpySQGtsc7D/VwsKynKFP9kJxdgpjs0ZpHR4vadAfgjEGe1vneQGmr+/eMI2zXU5+8Xr/Szg9s/vH1lVx28JxvPbVy1hS7n1NlUAqTA9eB62OLidPbazmip+9zQOr9jA+xx3s//iFRT2f9xsfmUx+WhLffmkX3T7sav7lGwdJT47nC5eVX/BYQXoyT941n44uJ3c9uSViaq07XYZH11aS5OPO1IGkJcXziYvH8srOk37vKQkkT3Be5OdF3N4WlOWwuaoxLFNZ4UaD/hDaHU46ulzkpvY/0wcoz0/js4tLeW7LMfacOJda6Ohy8iNrdu/odvHs5xfyoxtnkurD7sNA8XTQCqTObidPW8H+/728h5KcUTz7+XPBvvcF8IzkBL7/sensOXGGJ71MiXnsONbEG3tPc8+lE8hM6T8tNqkwnd/cfglH7G184fdbw76FoMtl+Pafd/HmvtN845rJAf/Z+Myi8TicLp4Po5LLmyobSIqPC0g+32N+aQ71rZ099azUwDToD+HcGv3BSyV8ZdkkskYl8MO/updwbjvSwHX/+S6/W1fFpxeM47WvXcaSIZphjISC9OSA5vSNMXzuyS187+U9FGeP4pnPL+T5LyxmycS8AXcaXztjNFdNKeCXbxwcVtOPX7xxkOyUBO5aWjroeUvK8/jZTbN5r7KBb72wM2xnf8YYfvjKXv649Rj/etVE7rlsQsDf46LCdBaW5fDMpiNhs7plU5Wdi8dlD6uY3FAW6Hp9r/nTGH2yiGzv9e+MiHxVRHJE5A0ROWR9zbbOFxF5SEQqRGSniFwcuI8RPPU9u3EHnukDZKYk8PVrJrOpqoF7ntrKTf+7kc5uF898fiE//vhMn2qLBEOhNdMP1GamjZV21lfYuf/aKfzpnxezdJBg7yEi/OBj0zEGHnh5t1dBeXNVA2sP1vEvV5STnjz0xe8b547lG9dcxF+2n/D7wnGw/OL1gzy5oZrPLS3j61dfFLT3uX3xeI41nOWdg6Hvodt8tou9J8+wcEJg8vke5fmp5KYmDpjXd7oMdS2d7DnRzNsHalm973TYTgaCzedIZIw5AMwBEBEb7sbnL+Fug7jaGPOgiNxv3f8WcC0wyfq3EHjE+hrWeuru9LN6p69b55fw+41HeHNfLZ9eOI5vXzc1bIK9R2FGMt0uQ0O7Y9DrFN56eHUFBelJ3LmkdFg1hEpyUvja1ZP4yav7eW3PaZYPUlHSGMPPXztAfnoSty8q9fo9vnTlRGoaz/Jfayoozh7FpxaM8/q5wfY/b1fwX2sq+NT8Er53w9Sg1l+6Ztpo8tOTeHrjEb9KHgTC1uoGjAnM+vzeRIT5pTm8e6ien722n7qWTmpbOnu+2ls76TvPeeGfFzOvNLC/fCJBoCLSMuCwMeaIiKwArrCOrwTexh30VwBPWc3Q3xORLBEZY4w5GaAxBIW91buZPriXDj75ufnUtXQyqzgryCPzTc8GrTODX5z2xtbqBjZW2vnu9VN92kF619IyXvrgBN9ftYelE3MHnMGvq6hnc3UDP1wxfViNNkSEf79xBieaO/jOX3YzY2wmM8YGLo/sq5UbqvnpPw6wYk4RP/74zKAX3EuMj+PWBeN4+K1DHLW3My43JajvN5hNVQ0k2uKYOy4r4K995ZR8/rHnFI+8fZi8tCQKMpIoSE9iRlEm+enu+/lpSSQn2rjriS1sP9akQd8PnwL+YN0u7BXITwGeqcVYoPfVpBrr2HlBX0TuBe4FGDcu9DMzu7XqIWeQC7m9jckcxZjMUcEckl/yPRu0WjqYRoZfr/XwWxXkpiby6YW+fZ8SbHH85OMz+MQjG/jF6wf5/semX3COZ5Y/NmsUt8wv8ek9Hr51Lgt/8ibPbTnKj8bO9GmsgfL81mM8sGoPV08r5OefnI0tbmQqrN66oIT/XlPBM5uP8G/XTh2R9+zPpko7c0qy/CozMZBb5o9j+fQxpCXHD/nftSgzOewL0gWL3xdyRSQR+Bjwp76PWbP6YSXOjDGPGmPmGWPm5ef7vzPRX/WtnaQnxQflhzQUPDP9443eX0Dtz45jTbxzsI67Ly3zazPR3HHZg67df3NfLTtqmrlv2USfL/xljkrg6mmj+dvOkwFpfuOrV3ae4P4Xd3LppDz+69NzA7IxyVtjMkdx9dRCnt9yLGRVSVs7u9l9IvD5/N4yUxK8+kU6qziLnTVNQRtHOAvET921wPvGGM/+99MiMgbA+uq5enQc6D1VK7aOhTX7IBuzItGYzFGMz03ht+9Wctbh+//8D79VQeaoBD67uNTvMXnW7v/bn89fu+9yGX7x+gFKc1P4p4uL/XqPFbOLaGzvYt2h0PSPXb3vNF99bjvzxufw6O3zArpyxVu3Lx5PY3sXr+4KTUZ1q1UfJ9D5fF/MKsnkiL09YjqMBVIggv6tnEvtAKwC7rBu3wG83Ov4Z61VPIuA5nDP54O7lv5QyzUjiS1OePATszhibx9wM9lQ9p44w5v7TvO5pWUBuVDtWbu/9+T5a/f/tusk+0+18LWrLyLez1nxZRflkzkqgZe3j/w8Y31FPf/yzPtMK8rgsTvnDbsBeKAsKc9lQn5qyArTbapqID5OuHh8Vkjev7fZ1jW3nTFYh9+v/5NEJBW4Gvhzr8MPAleLyCHgw9Z9gFeBSqAC+C3wRX/ee6TYWx2DbsyKRIvLc7lt4TgeX1/F+0cbh/38/15TQVpSPHcuKQ3YmDxr93/x+kFqGtvpdrr41ZsHmVyYzkdnFfn9+onxcVw3cwyv7z09ouWGtx1p5J6ntlKWm8rKuxZ4tdw0WESEzywczwdHm9gdgmC3qdLOrOLMgNQW8tdMa2PYzjCsSxRsfgV9Y0ybMSbXGNPc65jdGLPMGDPJGPNhY0yDddwYY75kjCk3xsw0xmz1d/AjwV13J3pm+h73XzuF0RnJfPOFncPatVpR28Kru09yx5LxA+6K9YVn7T7AAy/v4aUPjlNZ18bXrr6IuABd7Fwxp4h2h5M3943cevUHVu0mNy2Rpz+/gOwwmDz80yXFjEqw8fQI1+Npd3Szs6aZhRNCn9oB91+XE/JTY/Jiru7IHYTTZWho6yQvinL6HunJCfzkEzOpqG3l4dUVXj/vv96qIDnexueWlgV8TCU5KXz96otYvb+WH/x1LzPHZvKR6YFbV76gNIfRGcmsGqEUT2Obg93Hz3DzJSU9Za1DLXNUAjfOLeLlHcdHtDbR+0ea6HaZgBVZC4TZMXoxV4P+IJraHbgMUZfe8bhicgH/dHExj7xz2Ks/96vr21i14wSfWTQuaH/93LW0lKljMmjt7Ob/XHNRQNewx8UJH5tTxNsH6kbkAt7GSjsASyaGx+zW4zOLxtPR5eKF92tG7D03VdmxxUlYrYufVZxJbUsnp5ojv5PccGjQH4RnjX40pnc8vnfDVLJTEvnmCzuHXM74P29XEG+LC0qNGI94Wxz/+5mL+cnHZ3L5RYFfsvux2UV0uwx/330q4K/d14bD9aQm2sJuo970okwuHpfF7987MmK9hd+rtDOjKCOsdqh7vi87Ymy2r0F/EPXD2I0bqbJSEvnRjTPYe/IMj66tHPC8Yw3t/Pn949w6P/ipivG5qXx64big7FSdXpRBeX4qfxmBFM+GCjsLJ+SO6Hp8b92+eDxV9W1sOGwP+nt1dDnZcSx88vke04syiI+TmEvxhN9PYxjpqbsTxTN9gOUzRnP9zDH855uHOHS6pd9zfrP2MCLwhcsvrGMfSUSEFXPGsrmqgRPDqPA5XCebz1JZ38aSANaMD6RrZ4whJzWRp9+rDvp7vX+0EYfTFVb5fHA3FbqoMJ2dMXYxV4P+IHrq7kRpTr+3739sOqlJNr754s4LSvCeau7g+S013HRJCUVZ4Vtiwlsr5riXgP51R/Cahm+osPL5IWqWM5TkBBs3zyvhjb2nOdkcvF9+4K6fHyeEVT7fY3ZJJjtrmmOq4qYG/UHY2xzEiTsFEu3y05N44KPT+eBoE0+srzrvsd+sPYzTGP4lwmf5HuNzU5lTksXL24MX9NcfricnNZEpo9OD9h7+um3hOAzw7KajQX2fTVV2phVljGg/aG/NKs6i+WwXR+yR1V7THxr0B1Hf6iAnNXHEimKF2oo5RSybUsDPXz/AEbu7A1FdSyfPbjrKjXPGhrQ6Y6CtmFPE3pNnBkxn+cMYw8bDdhZPyA3YHoNgKMlJ4arJBfxh8zEc3cGpSdTZ7eSDo01hUXqhP57uXbF0MVeD/iDsrZ3kelFHP1qICD/++EwS4uL41os7cbkMv1tXicPp4otXRscs3+P6WWOIE1gVhBRPVX0bJ5s7wm6pZn8+s2g89a2drDkQnA1rO44109kdfvl8j4sK00mKj4upvL4G/UHY26Kr2Jo3Rmcm853rp/JeZQOPvHOYpzce4YZZRZTnp4V6aAFVkJ7M0ol5vLz9RMDzuZ4VMeGaz+/tQ5PySE20Ba0Q3aZKOyLn2hmGmwRbHNOLMmJqBY8G/UHYW6Or2Jq3bplfwtKJufzstQO0O5x8+cqJoR5SUHxsdhFHG9rZHuD6KxsO11OUmUxpBKTDEmxxLCjLYX1FkIJ+VQOTC9PD+rrYrOIsdh1vPq/CazTToD+IaCy25g0RdyXOlEQb180czeQwvhjpj4/MGE1ifFxAL+i6XFY+v3zoXsHhYunEPCrr2wK+hLXL6WLbkUYWhdn6/L7mlGTR0eXiUG1rqIcyIjToD6Cjy0lLZ3dU1t3xRklOCmu+cQW/umVOqIcSNBnJCSybUsArO08EbJa379QZGtu7WBoB+XyPpRPdaahAz/Z31jRztssZtvl8D8/F3FhJ8WjQH0BDDJRgGEphRnJImn2MpBVziqhvdQRsZ2q4r8/vz+TCdHJTEwO+O3dTlfv1wjWf71Gam0p6cnzMVNzUoD8Az27cWEzvxJIrJheQnhQfsBTPhsP1TMhPZXRmeFTV9EZcnLBkYh7rKuoDelF7U2UDkwrSwn7iFBcnzCrO1Jm+N0QkS0ReEJH9IrJPRBaLSI6IvCEih6yv2da5IiIPiUiFiOwUkYsD8xGCo77NU3cnvH9glX+SE2wsnzGa1/ac8rt3bJfTxeaqBpZG0CzfY2l5LnUtnVQEKK/d7XSxtbohqP1wA2lWcRb7T7aErH/wSPJ3pv+fwD+MMVOA2cA+4H5gtTFmErDaug/uXrqTrH/3Ao/4+d5Bda7ujs70o92Nc8fS2tnNW/v9W6u+41gTbQ5n2NbbGYwnr78uQHn9PSfO0OZwhu2mrL5mF2fS7TLsO3km1EMJOp+DvohkApcBjwEYYxzGmCZgBbDSOm0lcKN1ewXwlNVB6z0gy9NAPRz11N3RmX7UWzQhl/z0JL/752447F6TvjgCg35JTgrjclJYXxGYvP57Vi+BSJrpAzGxScufmX4ZUAc8ISIfiMjvrJ65hb0anp8CPK2PxgLHej2/xjp2HhG5V0S2isjWuro6P4bnH3ubg6T4OFJD1MRajRxbnPDRWUWs2V9H81nfu0mtr6hnelFGWK9JH8zSiXlsqrQHZCXTpqoGJuSlhk3HsKGMyUwmLy0pJsox+BP044GLgUeMMXOBNs6lcgB3X1xgWFeGjDGPGmPmGWPm5ecHvomGt+pbO8lLS4qYtdbKPyvmFOFwunjNx+YqZx3uGjORtGqnr6UTc2np7Gann03TnS7DlqrIyeeDe2/K7OJMnekPoQaoMcZssu6/gPuXwGlP2sb66kmUHgdKej2/2DoWluytsVeCIZbNKs6kNDeFl3f49iO59UgDDqcrIvP5HoutTVQb/Mzr7zt5hpbO7ojJ53vMKs7icF0rrZ3doR5KUPkc9I0xp4BjIjLZOrQM2AusAu6wjt0BvGzdXgV81lrFswho7pUGCjv2tk5drhlDRISPzRnLhsN2Tp8Zfs/U9RV24uOE+WFYM95buWlJTBuT4ffF3EjL53vMKsnEGNgV5bN9f1fv/CvwjIjsBOYAPwEeBK4WkUPAh637AK8ClUAF8Fvgi36+d1C5Z/p6ETeWrJhThDHwzHtHhv3cjYfrmTsui9Qw6gHri6UTc3n/SBNnHb4vXdxU1cD43BTGZEZWw53ZPRdzm0I6jmDzK+gbY7Zb+fdZxpgbjTGNxhi7MWaZMWaSMebDxpgG61xjjPmSMabcGDPTGLM1MB8h8Iwxmt6JQeX5aXx0dhGPvHN4WHX2m892set4c0Tn8z2WTszD4XSxpbrBp+e3dnaz8bA9ItNcOamJFGePivq8vu7I7UdLZzcOp4u8GKqlr9we+Og0UpPi+VY/bSMHsqnSjssQkYGurwVlOSTYhPWHfUvxvLithtbObm6ZPy7AIxsZs4uzAl51tbfntxxj9b7TQXt9b2jQ70dPCQad6cecvLQk/t8N03j/aBNPb6z26jkbDttJTohj7rjs4A5uBKQkxjN3XHZPDaHhcLkMKzdUM7skizklWYEf3AiYXZLJ8aazPft0Aqnd0c13/7Kbe5/exut7fFslFgga9PuhG7Ni28fnjuWyi/L56WsHOO5FueENh+uZX5pDYnx0/O+0tDyP3SeaaWp3DOt571bUU1nfxl1LSoMzsBEQzE1amyrdK7zy0hL58h8+YIOPf035Kzp+Svuobeng1kff4429vv0ZVa/F1mKaiPCTj88A4Dsv7Rq0CFltSwcHT7f2lDGIBksn5mIMbBxm1c0n11eRl5bEdTPDdqP9kGaMzUQkOD1z3zlYR1J8HKu+/CHKclO5Z+VWdgQxlTSQqAz6maMS2FRlZ5ePm0zsVrG1PJ3px6zi7BT+70cm8/aBukErcG7saY0Y+fl8j9klWe4WisNYulld38bbB+u4beG4iP6LJy0pnon5aUGZ6a89VMfCCbkUZiTz1N0LyElL5M4nNg9r0UAgRO53ZxBJ8TbG5aRwuM63ioGenH6OzvRj2mcXlzKnJIsf/HXPgDneDRV2MpLjmV6UOcKjC54EWxwLJ+QOq77+UxuPYBPhtoWReQG3t1nFWeysaQpomemaxnYq69q4bJL7L8LCjGR+f/dC4m1x3P7YZo41tAfsvYYSlUEf3MvvDvtYJtbe2klGcnxEz1iU/2xxwk9vmkVrZzc/fGVvv+esP1zP4vJcbHHRVa5j6cQ8qurbvLqm0dbZzZ+2HuO6mWMoyIiMWjuDmV2SSX2rgxPNw9+kN5C1B91/NV1+0bnSMuNzU/n93Qs52+Xk9sc2UdsSuPcbTNRGtfKCNKrq27xedtdbfZtDUzsKgIsK0/niFRN5efsJ3tp//jWiYw3t1DSejYr1+X152j1600Lxz+/X0NLZzZ1LS4M8qpHRczE3gPn2tQfrGJOZzMSCtPOOTx6dzhN3zef0mU4++9hmvwr+eSt6g35+Kp3dLp+aPdtbO3W5purxxSvLmVSQxndf2n1eXRZPQIykfrjemlyYTl5a4pB1eIwxPLmhmlnFmcyN0GWafU0dk06CTQLWPrHb6WL94Xoum5TfbwHHi8dl8+hnL+FwXSufe3IL7Y7g1v6J4qDv/o1a4UNe397qIFc3ZilLUryNB/9pFifPdPDTf+zvOb7+sJ2C9KSen7VoIiIsKc9j/WH7oLntdRX1HK5r484lpVFTkTYp3saU0RkBK8ew/VgTLR3dXHbRwFWDL52Uz0OfmssHRxv5l9+/j6Pb//LWA4n6oO9LXt/epiUY1PkuGZ/NHYtLefq9I2ytbsAYw8bD9Swpz42aYNfX0onuFoqHBvl/6Mn11eSlJXL9rMhdptmfWcWZ7KppxuVDerivtQfriBP40BDLeq+dOYYHPzGLdw7W8bXnt/uUmvZG1Ab97NREclITOVzXNqzndTtdNLZrsTV1of/7kckUZY7iWy/uZPfxM9S3OlgSRevz++ppoXio/xTPUXs7bx2o5dMLxpEUH13NhmYXZ9HS2U2VfXjxoz/vHKpndkkWmSkJQ5578/wSvnPdVP628yTf/cvugK4g8ojaoA/uvP5wl202tndhjPbGVRdKTYrnJ5+YyeG6Nv71D+8D0bU+v6/i7BTG56YMuHP0qY3V7mWai8aP8MiCb1aJewmuvymexjYHO2uauGyS9w2h7rlsAl+6spxEmxCEmB/tQT+NymEGfc/GLM3pq/5cflE+n5g7lmp7O+NzUyjOTgn1kIJq6cQ83qtsuKCFYltnN3/ceozlM0ZTGAXLNPuamJ/GqAQbO475dzF3XUU9xjBoPr8/37hmMt//2HTigrAUOOqDfn2rY1g1RLTYmhrK926YRn56EldNKQj1UIJuaXkerZ3dF6xkeemD47R0dHNXlCzT7CveFseMsRl+l2NYe7COjOR4ZhcPb/OeiATtWpFfQV9EqkVkl4hsF5Gt1rEcEXlDRA5ZX7Ot4yIiD4lIhYjsFJGLA/EBBlNekAowrLx+faunBIMGfdW/7NRE1nzjCr593dRQDyXoFpfnInJ+C0Vj3NU0Z4zN4OIoqCw6kNnFWew9cYYuHxvFG2NYe6iOD03KI94WPvPrQIzkSmPMHGPMPOv+/cBqY8wkYDXnmqVfC0yy/t0LPBKA9x5UzwqeYaR4emb6mt5Rg0hLiichjP5HDpac1MQLWihuOGznUG0rdy4pi9qVSwCzSrLo7HZx4JRvtXEOnm7l9JnOYeXzR0IwfmpXACut2yuBG3sdf8rqoPUekOVpoB4sxdkpJNrihhf02zqxxQmZo4a+0q5ULFg6MY8Pjjb1bBp6Yn01OamJ3BBlyzT7umR8NiLw6i7fWnmvPVgHDD+fH2z+Bn0DvC4i20TkXutYYa+G56eAQuv2WOBYr+fWWMfOIyL3ishWEdlaV1fn1+BscUJZXiqHa71P79hbHeSkJgblAopSkehcC8VGjjW0s3r/aW5dUEJyQnQt0+xrbNYobphVxMoN1TS2Da+3ALirak4sSKMoK7x6Bfsb9D9kjLkYd+rmSyJyWe8HjXuR6bAWHRljHrX67s7Lz/f/N2R5QeqwVvDUtzq0jr5SvcwvzSbBJmyoqOfp944QJ8JnonCZZn/uu2oi7V1OfreucljPO+twsqmqIexSO+B/Y/Tj1tda4CVgAXDak7axvtZapx8HSno9vdg6FlTl+WkcaWj3eluzva1Ti60p1UtKYjwXj8tm9f5antt8lOXTRzMmM7xmr8EyqTCd62eOYeWGI8Oa7W+qsuPodnHZReG3ec/noC8iqSKS7rkNXAPsBlYBd1in3QG8bN1eBXzWWsWzCGjulQYKmvL8NJwuw9EG71I89lYtwaBUX0sn5lFR28qZjuippumt+5ZNos3RzWPrqrx+ztqD9STGx7GwLPw27/kz0y8E1onIDmAz8DdjzD+AB4GrReQQ8GHrPsCrQCVQAfwW+KIf7+21nsJrXub17a2dunJHqT48JRmmjclg3vjoXabZn4sK07lu5hie3FDt9Z6ftYfqWFiWw6jE8LvuEe/rE40xlcDsfo7bgWX9HDfAl3x9P19NyPes1R86r3/W4aTN4dSZvlJ9zC7O5NJJeVFVTXM47rtqEq/uOslj66r4P9dMHvTcE01nqaht5ZZ5JYOeFypRv9A4NSmeMZnJXgX9c71xNegr1Vu8LY6n717IsqmFQ58chSaPTue6GWN4Yv3Qs/1wXarpEfVBH6zWiV7syvVszNILuUqpvu5bNonWzqFz+2sP1TE6I5mLCsOzz0KMBP1UKmtbhyxT2lNsTYO+UqqPyaPdK3meHGS23+10se5QPZdOygvbNFhsBP2CNFo6u6lr6Rz0vPqeEgya3lFKXehfl02kpbObxweY7e+oaebMEF2yQi02gr6XrRO1wqZSajBTRmdw3czRPLG+mub2C5uYrz1Yh3jRJSuUYiroD5XXt7d2kpJoIyXR50VNSqkod9+ySbR0dvPY+gtn+2sP1TGrOIvsMM4WxETQL8xIIjXRNmS/XO2Nq5QaypTRGVw7YzRPrKs6b7bf3N7FjmNNXD4pfGf5ECNBX0QoL0gbctlmvW7MUkp5ob/Z/rqKelw+dMkaaTER9MHTOnGo9I5D1+grpYY0dUwGy6eP5on1VTSfdc/21x6sIz05njklWaEd3BBiKOincrzpbE9N8P7Y23Smr5Tyzn3LJtHS4V7J4+mStbQ8vLpk9Se8RxdAnou5A832jTFabE0p5bVpRe7Z/uPrq3j/aCMnmzvCPrUDsRT0CwZvnXjmbDfdLqMbs5RSXvPM9r/y3HaAsCyl3FfMBP3xuSnEycDLNuu17o5SapimFWXwkemF1DSeZUJ+KsXZKaEe0pBiJugnxdsYl5My4ExfG6IrpXxx37JJAFweAakd8KO0ciQqz08bcK2+vdVTd0dn+kop700vyuSZzy9k2piMUA/FK37P9EXEJiIfiMgr1v0yEdkkIhUi8kcRSbSOJ1n3K6zHS/197+EqL0ijqr4Np+vCwmv1bVqCQSnlm6UT88J6F25vgUjvfAXY1+v+fwC/MsZMBBqBu63jdwON1vFfWeeNqPL8VDq7XZxoOnvBY56Zfk5KZHzjlFLKF34FfREpBq4HfmfdF+Aq4AXrlJXAjdbtFdZ9rMeXyQjXHh2s8Jq91UF2SkLYr7FVSil/+Bvhfg18E3BZ93OBJmOMZwdUDTDWuj0WOAZgPd5snT9iegqv9ZPXt7d16nJNpVTU8znoi8gNQK0xZlsAx4OI3CsiW0Vka11dXSBfmuzURHJSE/tdtlnf6tA6+kqpqOfPTH8p8DERqQaew53W+U8gS0Q8q4KKgePW7eNACYD1eCZg7/uixphHjTHzjDHz8vMDvwSqPD+132Wb9tZObZOolIp6Pgd9Y8y/GWOKjTGlwKeAt4wxtwFrgJus0+4AXrZur7LuYz3+lhmqf2EQuAuv9Zfe0RIMSqnoF4yrlt8Cvi4iFbhz9o9Zxx8Dcq3jXwfuD8J7D6k8P436Vsd5PS67nC6a2rt0Y5ZSKuoFZHOWMeZt4G3rdiWwoJ9zOoBPBuL9/FFekAq4yzFcMt49s2/UNfpKqRgRc+sTz7VOPJfi8TRE17o7SqloF3NBvzg7hURb3HlB397mKcGg6R2lVHSLuaBvixPK8lI5XHtu2ea5Yms601dKRbeYC/rgzutXnpfe0Zm+Uio2xGbQz0/jSEM7jm73RuL6VgcJNiEjOaaKjiqlYlDMBn2ny3C0wZ3isbe6e+OOcCkgpZQacTEb9AEqrLy+bsxSSsWKmAz6E/I9a/XdeX17qxZbU0rFhpgM+qlJ8YzJTO4J+vWtDvJ05Y5SKgbEZNAHq3ViXRvGGKussgZ9pVT0i+Ggn0plbSttDicdXS5N7yilYkLsBv2CNFo6u9l/8gygG7OUUrEhdoO+tYJnU1UDgNbSV0rFhJgP+putoK85faVULIjZoF+YkURqoo1tRxoBLcGglIoNMRv0RYTygjRaO9093DWnr5SKBf40Rk8Wkc0iskNE9ojID6zjZSKySUQqROSPIpJoHU+y7ldYj5cG6DP4zJPiSUuKJznBFuLRKKVU8Pkz0+8ErjLGzAbmAMtFZBHwH8CvjDETgUbgbuv8u4FG6/ivrPNCqtzamav5fKVUrPCnMboxxnjqEydY/wxwFfCCdXwlcKN1e4V1H+vxZRLiCmeemb6mdpRSscKvnL6I2ERkO1ALvAEcBpqMMd3WKTXAWOv2WOAYgPV4M+7G6X1f814R2SoiW+vq6vwZ3pDKC6ygrxdxlVIxwq+gb4xxGmPmAMW4m6FP8XdAxphHjTHzjDHz8vPz/X25QY3PTSFOdKavlIodAekaYoxpEpE1wGIgS0Tirdl8MXDcOu04UALUiEg8kAnYA/H+vkqKt/G9G6Yxd1x2KIehlFIjxp/VO/kikmXdHgVcDewD1gA3WafdAbxs3V5l3cd6/C1jjPH1/QPlrqVlzCnJCvUwlFJqRPgz0x8DrBQRG+5fHs8bY14Rkb3AcyLyI+AD4DHr/MeAp0WkAmgAPuXHeyullPKBz0HfGLMTmNvP8Urc+f2+xzuAT/r6fkoppfwXsztylVIqFmnQV0qpGKJBXymlYogGfaWUiiEa9JVSKoZo0FdKqRgiYbA/akAiUgcc6eehPKB+hIcTDNHyOUA/SziKls8B+lmGa7wxpt86NmEd9AciIluNMfNCPQ5/RcvnAP0s4ShaPgfoZwkkTe8opVQM0aCvlFIxJFKD/qOhHkCARMvnAP0s4ShaPgfoZwmYiMzpK6WU8k2kzvSVUkr5QIO+UkrFkIgK+iKyXEQOiEiFiNwf6vH4Q0SqRWSXiGwXka2hHs9wiMjjIlIrIrt7HcsRkTdE5JD1NezbkQ3wOb4vIset78t2EbkulGP0loiUiMgaEdkrIntE5CvW8Uj8vgz0WSLqeyMiySKyWUR2WJ/jB9bxMhHZZMWxP4rIiPZrjZicvtWs5SDuDl01wBbgVmPM3pAOzEciUg3MM8ZE3IYTEbkMaAWeMsbMsI79FGgwxjxo/ULONsZ8K5TjHMoAn+P7QKsx5uehHNtwicgYYIwx5n0RSQe2ATcCdxJ535eBPsvNRND3RkQESDXGtIpIArAO+ArwdeDPxpjnROR/gR3GmEdGalyRNNNfAFQYYyqNMQ7gOWBFiMcUk4wxa3F3P+ttBbDSur0S9/+kYW2AzxGRjDEnjTHvW7dbcLcuHUtkfl8G+iwRxbi1WncTrH8GuAp4wTo+4t+TSAr6Y4Fjve7XEIE/CL0Y4HUR2SYi94Z6MAFQaIw5ad0+BRSGcjB++rKI7LTSP2GfDulLREpxd7XbRIR/X/p8Foiw742I2ERkO1ALvAEcBpqMMd3WKSMexyIp6EebDxljLgauBb5kpRqigtXwPjLyhhd6BCgH5gAngV+EdDTDJCJpwIvAV40xZ3o/Fmnfl34+S8R9b4wxTmPMHKAYd7ZiSmhHFFlB/zhQ0ut+sXUsIhljjltfa4GX6KevcIQ5beViPTnZ2hCPxyfGmNPW/6gu4LdE0PfFyhu/CDxjjPmzdTgivy/9fZZI/t4YY5qANcBiIEtEPP3JRzyORVLQ3wJMsq58JwKfAlaFeEw+EZFU6wIVIpIKXAPsHvxZYW8VcId1+w7g5RCOxWeeAGn5OBHyfbEuGj4G7DPG/LLXQxH3fRnos0Ta90ZE8kUky7o9CvcilH24g/9N1mkj/j2JmNU7ANYSrV8DNuBxY8yPQzsi34jIBNyze4B44NlI+iwi8gfgCtwlYk8DDwB/AZ4HxuEuh32zMSasL5IO8DmuwJ0+MEA18IVeOfGwJSIfAt4FdgEu6/C3cefCI+37MtBnuZUI+t6IyCzcF2ptuCfYzxtjfmj9//8ckAN8AHzGGNM5YuOKpKCvlFLKP5GU3lFKKeUnDfpKKRVDNOgrpVQM0aCvlFIxRIO+UkrFEA36SnnBqvD4jVCPQyl/adBXSqkYokFfqQGIyHdE5KCIrAMmW8fuEZEtVo30F0UkRUTSRaTKKh2AiGT0vq9UONGgr1Q/ROQS3KU+5gDXAfOth/5sjJlvjJmNe0v93Vb537eB661zPmWd1zWig1bKCxr0lerfpcBLxph2q8Kjp87TDBF5V0R2AbcB063jvwPusm7fBTwxoqNVyksa9JUanieBLxtjZgI/AJIBjDHrgVIRuQKwGWPCuhiYil0a9JXq31rgRhEZZVVE/ah1PB04aeXrb+vznKeAZ9FZvgpjWnBNqQGIyHdwl76tBY4C7wNtwDeBOtwVLNONMXda548GqnD3d20KwZCVGpIGfaUCRERuAlYYY24P9ViUGkj80KcopYYiIg/jbn15XajHotRgdKavlFIxRC/kKqVUDNGgr5RSMUSDvlJKxRAN+kopFUM06CulVAz5/wEpjEtbngmxCwAAAABJRU5ErkJggg==\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"image","arguments":{}}},"output_type":"display_data","data":{"image/png":"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\n"},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["## Your Turn: Q12: Visualizing Hourly 404 Errors\n\nUsing the DataFrame `not_found_df` you cached in the Q10, group and sort by hour of the day in increasing order, to create a DataFrame containing the total number of 404 responses for HTTP requests for each hour of the day (midnight starts at 0). \n\n- Remember to check out the [__hour__](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.hour) function and use it (we have already imported __`pyspark.sql.functions`__ as __`F`__ earlier\n- Output should be a bar graph displaying the total number of 404 errors per hour"],"metadata":{"colab_type":"text","id":"lRY2RYHeXvED","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8adbcb9a-4a8e-4508-ae63-a6fbac021e5f"}}},{"cell_type":"code","source":["# TODO: Replace <FILL IN> with appropriate code\n\nhour = F.udf(lambda x: x.hour)\nhourly_avg_errors_sorted_df = (not_found_df.select(hour(not_found_df['time']).alias('hour')).groupBy('hour').count().sort('hour'))\n\nhourly_avg_errors_sorted_df = hourly_avg_errors_sorted_df.toPandas()\nhourly_avg_errors_sorted_df.T"],"metadata":{"colab_type":"code","id":"T7Y0Dbz3XvEF","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"03b44bf1-59da-4eca-90c2-0a7fe50ed1a4"},"colab":{},"outputId":"873d829e-6b6d-4dc1-b894-0796ef91aec1"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>hour</th>\n      <td>0</td>\n      <td>1</td>\n      <td>10</td>\n      <td>11</td>\n      <td>12</td>\n      <td>13</td>\n      <td>14</td>\n      <td>15</td>\n      <td>16</td>\n      <td>17</td>\n      <td>18</td>\n      <td>19</td>\n      <td>2</td>\n      <td>20</td>\n      <td>21</td>\n      <td>22</td>\n      <td>23</td>\n      <td>3</td>\n      <td>4</td>\n      <td>5</td>\n      <td>6</td>\n      <td>7</td>\n      <td>8</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>count</th>\n      <td>774</td>\n      <td>648</td>\n      <td>1087</td>\n      <td>1160</td>\n      <td>1308</td>\n      <td>1151</td>\n      <td>1274</td>\n      <td>1382</td>\n      <td>1181</td>\n      <td>1203</td>\n      <td>930</td>\n      <td>852</td>\n      <td>868</td>\n      <td>815</td>\n      <td>879</td>\n      <td>915</td>\n      <td>939</td>\n      <td>603</td>\n      <td>351</td>\n      <td>307</td>\n      <td>269</td>\n      <td>458</td>\n      <td>705</td>\n      <td>840</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>hour</th>\n      <td>0</td>\n      <td>1</td>\n      <td>10</td>\n      <td>11</td>\n      <td>12</td>\n      <td>13</td>\n      <td>14</td>\n      <td>15</td>\n      <td>16</td>\n      <td>17</td>\n      <td>18</td>\n      <td>19</td>\n      <td>2</td>\n      <td>20</td>\n      <td>21</td>\n      <td>22</td>\n      <td>23</td>\n      <td>3</td>\n      <td>4</td>\n      <td>5</td>\n      <td>6</td>\n      <td>7</td>\n      <td>8</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>count</th>\n      <td>774</td>\n      <td>648</td>\n      <td>1087</td>\n      <td>1160</td>\n      <td>1308</td>\n      <td>1151</td>\n      <td>1274</td>\n      <td>1382</td>\n      <td>1181</td>\n      <td>1203</td>\n      <td>930</td>\n      <td>852</td>\n      <td>868</td>\n      <td>815</td>\n      <td>879</td>\n      <td>915</td>\n      <td>939</td>\n      <td>603</td>\n      <td>351</td>\n      <td>307</td>\n      <td>269</td>\n      <td>458</td>\n      <td>705</td>\n      <td>840</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["hourly_avg_errors_sorted_df.plot(kind='bar')"],"metadata":{"colab":{},"colab_type":"code","id":"R1vsAPs1XvEJ","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b39e931-d433-467e-a14b-c7d54172ab7e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[150]: <AxesSubplot:>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[150]: <AxesSubplot:>"]},"transient":null},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"data:image/png;base64,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\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"image","arguments":{}}},"output_type":"display_data","data":{"image/png":"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\n"},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["# Load Data"],"metadata":{"colab_type":"text","id":"GYWAsa8mY425","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6b2cdc2a-d2d1-44d1-8246-3c5587e13e06"}}},{"cell_type":"markdown","source":["Up till now, you have completed data extraction, data transformation, and some exploratory data analysis. In the end of this project, we will complete the last step of ETL process: data loading, so the data after  your processing, wrangling, cleaning, can be used by either yourself or other colleagues later. Since we have gone through a few iteration of data processing and data wrangling, it is a good idea to make sure which one is the current dataframe you want to store and load."],"metadata":{"colab_type":"text","id":"woEUWlYCY9h0","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c2585de-a16c-42ca-aec7-c6425fa2da0a"}}},{"cell_type":"markdown","source":["## Your Turn: Q13: Check data integrity before loading"],"metadata":{"colab_type":"text","id":"gde50KFwZCyR","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"86efdaa2-2b4f-40e3-ad4a-58c12ec1f46a"}}},{"cell_type":"code","source":["# TODO: Review the data frame you will like to store and load. Replace <FILL IN> with appropriate code\n\nprint(logs_df.count())\nprint(logs_df.columns)"],"metadata":{"colab_type":"code","id":"Jp9HtJDZZDgm","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"73bbe087-a869-441e-9dcf-0dd484a37b7f"},"colab":{},"outputId":"d94fda2f-0e91-401a-eb33-dfa58e5b8f0d"},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"3461613\n['host', 'method', 'endpoint', 'protocol', 'status', 'content_size', 'time']\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["3461613\n['host', 'method', 'endpoint', 'protocol', 'status', 'content_size', 'time']\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["To save your dataframe in CSV file format, you call simply replace the name of the dataframe and assign file name in the following:"],"metadata":{"colab_type":"text","id":"6KT_ajIJZFsi","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6fb4db34-aab2-437d-be9d-1bf03da146ec"}}},{"cell_type":"markdown","source":["## Your Turn: Q14: Save your data as a CSV file"],"metadata":{"colab_type":"text","id":"GuiBAZEqZJT1","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d749b04b-fb51-48bb-9584-ee5200ccdcba"}}},{"cell_type":"code","source":["# TODO: Review the data frame you will like to store and load. Replace <FILL IN> with appropriate code\n\nlogs_df.write.save(\"dbfs:/FileStore/tables/nasa_http_log.csv\", format = 'csv')"],"metadata":{"colab":{},"colab_type":"code","id":"DHLpKGA7ZP8P","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a47715da-abd2-439c-bad3-e9dffee6340f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n\u001B[0;32m<command-3048127638877901>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# TODO: Review the data frame you will like to store and load. Replace <FILL IN> with appropriate code\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mlogs_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"dbfs:/FileStore/tables/nasa_http_log.csv\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mformat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'csv'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/databricks/spark/python/pyspark/sql/readwriter.py\u001B[0m in \u001B[0;36msave\u001B[0;34m(self, path, format, mode, partitionBy, **options)\u001B[0m\n\u001B[1;32m    738\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    739\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 740\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    741\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    742\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0msince\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1.4\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1303\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1304\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    115\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOUTPUT_CONVERTER\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    325\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 326\u001B[0;31m                 raise Py4JJavaError(\n\u001B[0m\u001B[1;32m    327\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n\n\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o3214.save.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.jobAbortedError(QueryExecutionErrors.scala:513)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:347)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:198)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:126)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:124)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:138)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:130)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:169)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:316)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:143)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:113)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:266)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:130)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:485)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:86)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:485)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:268)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:264)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:461)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:126)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:324)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:126)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:111)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:102)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:153)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:947)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:421)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:390)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:250)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 187.0 failed 1 times, most recent failure: Lost task 0.0 in stage 187.0 (TID 821) (ip-10-172-192-231.us-west-2.compute.internal executor driver): org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.taskFailedWhileWritingRowsError(QueryExecutionErrors.scala:517)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:442)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$20(FileFormatWriter.scala:323)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:153)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:122)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:93)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:824)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1621)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:827)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:683)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: 'ValueError: invalid literal for int() with base 10: ''', from <command-3048127638877849>, line 17. Full traceback below:\nTraceback (most recent call last):\n  File \"<command-3048127638877849>\", line 17, in parse_clf_time\nValueError: invalid literal for int() with base 10: ''\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:689)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:642)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:758)\n\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:90)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$2(FileFormatWriter.scala:422)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1655)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:429)\n\t... 19 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2920)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2914)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2914)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1334)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1334)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1334)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3123)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3111)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1096)\n\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:2494)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2477)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:312)\n\t... 43 more\nCaused by: org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.taskFailedWhileWritingRowsError(QueryExecutionErrors.scala:517)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:442)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$20(FileFormatWriter.scala:323)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:153)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:122)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:93)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:824)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1621)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:827)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:683)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.spark.api.python.PythonException: 'ValueError: invalid literal for int() with base 10: ''', from <command-3048127638877849>, line 17. Full traceback below:\nTraceback (most recent call last):\n  File \"<command-3048127638877849>\", line 17, in parse_clf_time\nValueError: invalid literal for int() with base 10: ''\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:689)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:642)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:758)\n\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:90)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$2(FileFormatWriter.scala:422)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1655)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:429)\n\t... 19 more\n","errorSummary":"org.apache.spark.SparkException: Job aborted.","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n\u001B[0;32m<command-3048127638877901>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# TODO: Review the data frame you will like to store and load. Replace <FILL IN> with appropriate code\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mlogs_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"dbfs:/FileStore/tables/nasa_http_log.csv\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mformat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'csv'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/databricks/spark/python/pyspark/sql/readwriter.py\u001B[0m in \u001B[0;36msave\u001B[0;34m(self, path, format, mode, partitionBy, **options)\u001B[0m\n\u001B[1;32m    738\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    739\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 740\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    741\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    742\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0msince\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1.4\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1303\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1304\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    115\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOUTPUT_CONVERTER\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    325\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 326\u001B[0;31m                 raise Py4JJavaError(\n\u001B[0m\u001B[1;32m    327\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n\n\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o3214.save.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.jobAbortedError(QueryExecutionErrors.scala:513)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:347)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:198)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:126)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:124)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:138)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:130)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:169)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:316)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:143)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:113)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:266)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:130)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:485)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:86)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:485)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:268)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:264)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:461)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:126)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:324)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:126)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:111)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:102)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:153)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:947)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:421)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:390)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:250)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 187.0 failed 1 times, most recent failure: Lost task 0.0 in stage 187.0 (TID 821) (ip-10-172-192-231.us-west-2.compute.internal executor driver): org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.taskFailedWhileWritingRowsError(QueryExecutionErrors.scala:517)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:442)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$20(FileFormatWriter.scala:323)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:153)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:122)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:93)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:824)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1621)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:827)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:683)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: 'ValueError: invalid literal for int() with base 10: ''', from <command-3048127638877849>, line 17. Full traceback below:\nTraceback (most recent call last):\n  File \"<command-3048127638877849>\", line 17, in parse_clf_time\nValueError: invalid literal for int() with base 10: ''\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:689)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:642)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:758)\n\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:90)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$2(FileFormatWriter.scala:422)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1655)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:429)\n\t... 19 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2920)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2914)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2914)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1334)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1334)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1334)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3123)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3111)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1096)\n\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:2494)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2477)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:312)\n\t... 43 more\nCaused by: org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.taskFailedWhileWritingRowsError(QueryExecutionErrors.scala:517)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:442)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$20(FileFormatWriter.scala:323)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:153)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:122)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:93)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:824)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1621)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:827)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:683)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.spark.api.python.PythonException: 'ValueError: invalid literal for int() with base 10: ''', from <command-3048127638877849>, line 17. Full traceback below:\nTraceback (most recent call last):\n  File \"<command-3048127638877849>\", line 17, in parse_clf_time\nValueError: invalid literal for int() with base 10: ''\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:689)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:642)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:758)\n\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:90)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$2(FileFormatWriter.scala:422)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1655)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:429)\n\t... 19 more\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# TODO: Check to see if you have stored and loaded the CSV file successfully by checking the first 5 rows. Replace <FILL IN> with appropriate code\nfrom pyspark.sql import SparkSession\nspark_session = SparkSession.builder.appName(\"nasa\").getOrCreate()\n\nspark_session\\\n\t.sparkContext\\\n\t.textFile('dbfs:/FileStore/tables/nasa_http_log.csv')\\\n\t.take(5)"],"metadata":{"colab":{},"colab_type":"code","id":"EJN6Xy76ZTkW","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"706816bb-6dfc-4b12-b633-9d8f2f105a9f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[185]: ['in24.inetnebr.com,GET,/shuttle/missions/sts-68/news/sts-68-mcc-05.txt,HTTP/1.0,200,1839,1995-08-01T00:00:01.000Z',\n 'uplherc.upl.com,GET,/,HTTP/1.0,304,0,1995-08-01T00:00:07.000Z',\n 'uplherc.upl.com,GET,/images/ksclogo-medium.gif,HTTP/1.0,304,0,1995-08-01T00:00:08.000Z',\n 'uplherc.upl.com,GET,/images/MOSAIC-logosmall.gif,HTTP/1.0,304,0,1995-08-01T00:00:08.000Z',\n 'uplherc.upl.com,GET,/images/USA-logosmall.gif,HTTP/1.0,304,0,1995-08-01T00:00:08.000Z']","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[185]: ['in24.inetnebr.com,GET,/shuttle/missions/sts-68/news/sts-68-mcc-05.txt,HTTP/1.0,200,1839,1995-08-01T00:00:01.000Z',\n 'uplherc.upl.com,GET,/,HTTP/1.0,304,0,1995-08-01T00:00:07.000Z',\n 'uplherc.upl.com,GET,/images/ksclogo-medium.gif,HTTP/1.0,304,0,1995-08-01T00:00:08.000Z',\n 'uplherc.upl.com,GET,/images/MOSAIC-logosmall.gif,HTTP/1.0,304,0,1995-08-01T00:00:08.000Z',\n 'uplherc.upl.com,GET,/images/USA-logosmall.gif,HTTP/1.0,304,0,1995-08-01T00:00:08.000Z']"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["Similarly, you can also store and load your dataframe as a JSON file by completing the following:"],"metadata":{"colab_type":"text","id":"nkz9rKU3ZV7S","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c80d7e17-ab1d-4303-96e1-60cee698860b"}}},{"cell_type":"markdown","source":["## Your Turn: Q15: Save your data as a JSON file"],"metadata":{"colab_type":"text","id":"l6N5oSjgZaiX","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b3b34e9b-adf9-4739-9a07-1b2822ae0953"}}},{"cell_type":"code","source":["# TODO: Review the data frame you will like to store and load. Replace <FILL IN> with appropriate code\n\nlogs_df.write.save(\"dbfs:/FileStore/tables/nasa_http_log.json\", format = 'json')"],"metadata":{"colab":{},"colab_type":"code","id":"nPp5cHZeZZCQ","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fcbf73b8-7521-4806-a961-69884e825f39"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n\u001B[0;32m<command-3048127638877905>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# TODO: Review the data frame you will like to store and load. Replace <FILL IN> with appropriate code\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mlogs_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"dbfs:/FileStore/tables/nasa_http_log.json\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mformat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'json'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/databricks/spark/python/pyspark/sql/readwriter.py\u001B[0m in \u001B[0;36msave\u001B[0;34m(self, path, format, mode, partitionBy, **options)\u001B[0m\n\u001B[1;32m    738\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    739\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 740\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    741\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    742\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0msince\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1.4\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1303\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1304\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    115\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOUTPUT_CONVERTER\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    325\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 326\u001B[0;31m                 raise Py4JJavaError(\n\u001B[0m\u001B[1;32m    327\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n\n\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o3246.save.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.jobAbortedError(QueryExecutionErrors.scala:513)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:347)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:198)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:126)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:124)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:138)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:130)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:169)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:316)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:143)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:113)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:266)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:130)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:485)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:86)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:485)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:268)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:264)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:461)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:126)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:324)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:126)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:111)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:102)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:153)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:947)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:421)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:390)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:250)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 189.0 failed 1 times, most recent failure: Lost task 0.0 in stage 189.0 (TID 824) (ip-10-172-192-231.us-west-2.compute.internal executor driver): org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.taskFailedWhileWritingRowsError(QueryExecutionErrors.scala:517)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:442)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$20(FileFormatWriter.scala:323)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:153)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:122)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:93)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:824)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1621)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:827)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:683)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: 'ValueError: invalid literal for int() with base 10: ''', from <command-3048127638877849>, line 17. Full traceback below:\nTraceback (most recent call last):\n  File \"<command-3048127638877849>\", line 17, in parse_clf_time\nValueError: invalid literal for int() with base 10: ''\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:689)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:642)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:758)\n\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:90)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$2(FileFormatWriter.scala:422)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1655)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:429)\n\t... 19 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2920)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2914)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2914)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1334)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1334)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1334)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3123)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3111)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1096)\n\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:2494)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2477)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:312)\n\t... 43 more\nCaused by: org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.taskFailedWhileWritingRowsError(QueryExecutionErrors.scala:517)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:442)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$20(FileFormatWriter.scala:323)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:153)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:122)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:93)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:824)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1621)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:827)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:683)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.spark.api.python.PythonException: 'ValueError: invalid literal for int() with base 10: ''', from <command-3048127638877849>, line 17. Full traceback below:\nTraceback (most recent call last):\n  File \"<command-3048127638877849>\", line 17, in parse_clf_time\nValueError: invalid literal for int() with base 10: ''\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:689)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:642)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:758)\n\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:90)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$2(FileFormatWriter.scala:422)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1655)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:429)\n\t... 19 more\n","errorSummary":"org.apache.spark.SparkException: Job aborted.","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n\u001B[0;32m<command-3048127638877905>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# TODO: Review the data frame you will like to store and load. Replace <FILL IN> with appropriate code\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mlogs_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"dbfs:/FileStore/tables/nasa_http_log.json\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mformat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'json'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\n\u001B[0;32m/databricks/spark/python/pyspark/sql/readwriter.py\u001B[0m in \u001B[0;36msave\u001B[0;34m(self, path, format, mode, partitionBy, **options)\u001B[0m\n\u001B[1;32m    738\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    739\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 740\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_jwrite\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msave\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    741\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    742\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0msince\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1.4\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1303\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1304\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    115\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.1-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOUTPUT_CONVERTER\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    325\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 326\u001B[0;31m                 raise Py4JJavaError(\n\u001B[0m\u001B[1;32m    327\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n\n\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o3246.save.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.jobAbortedError(QueryExecutionErrors.scala:513)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:347)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:198)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:126)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:124)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:138)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.$anonfun$applyOrElse$1(QueryExecution.scala:130)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:169)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:316)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:143)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:854)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:113)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:266)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:130)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$1$1.applyOrElse(QueryExecution.scala:126)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:485)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:86)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:485)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:268)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:264)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:461)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:126)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:324)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:126)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:111)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:102)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:153)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:947)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:421)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:390)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:250)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 189.0 failed 1 times, most recent failure: Lost task 0.0 in stage 189.0 (TID 824) (ip-10-172-192-231.us-west-2.compute.internal executor driver): org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.taskFailedWhileWritingRowsError(QueryExecutionErrors.scala:517)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:442)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$20(FileFormatWriter.scala:323)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:153)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:122)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:93)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:824)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1621)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:827)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:683)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: 'ValueError: invalid literal for int() with base 10: ''', from <command-3048127638877849>, line 17. Full traceback below:\nTraceback (most recent call last):\n  File \"<command-3048127638877849>\", line 17, in parse_clf_time\nValueError: invalid literal for int() with base 10: ''\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:689)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:642)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:758)\n\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:90)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$2(FileFormatWriter.scala:422)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1655)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:429)\n\t... 19 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2973)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2920)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2914)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2914)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1334)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1334)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1334)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3123)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3111)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:1096)\n\tat org.apache.spark.SparkContext.runJobInternal(SparkContext.scala:2494)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2477)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:312)\n\t... 43 more\nCaused by: org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.taskFailedWhileWritingRowsError(QueryExecutionErrors.scala:517)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:442)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$20(FileFormatWriter.scala:323)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$3(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.$anonfun$runTask$1(ResultTask.scala:75)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:55)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:153)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:122)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:93)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:824)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1621)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:827)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:683)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.spark.api.python.PythonException: 'ValueError: invalid literal for int() with base 10: ''', from <command-3048127638877849>, line 17. Full traceback below:\nTraceback (most recent call last):\n  File \"<command-3048127638877849>\", line 17, in parse_clf_time\nValueError: invalid literal for int() with base 10: ''\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:689)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:642)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:758)\n\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:90)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$2(FileFormatWriter.scala:422)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1655)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:429)\n\t... 19 more\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# TODO: Similarly, check the first 5 rows in the JSON file. Replace <FILL IN> with appropriate code\n\nspark_session\\\n\t.sparkContext\\\n\t.textFile(\"dbfs:/FileStore/tables/nasa_http_log.json\")\\\n\t.take(5)"],"metadata":{"colab":{},"colab_type":"code","id":"56w3oyaOZgiE","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a49d0695-265d-4077-9126-c731bef20d8b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[187]: ['{\"host\":\"in24.inetnebr.com\",\"method\":\"GET\",\"endpoint\":\"/shuttle/missions/sts-68/news/sts-68-mcc-05.txt\",\"protocol\":\"HTTP/1.0\",\"status\":\"200\",\"content_size\":\"1839\",\"time\":\"1995-08-01T00:00:01.000Z\"}',\n '{\"host\":\"uplherc.upl.com\",\"method\":\"GET\",\"endpoint\":\"/\",\"protocol\":\"HTTP/1.0\",\"status\":\"304\",\"content_size\":\"0\",\"time\":\"1995-08-01T00:00:07.000Z\"}',\n '{\"host\":\"uplherc.upl.com\",\"method\":\"GET\",\"endpoint\":\"/images/ksclogo-medium.gif\",\"protocol\":\"HTTP/1.0\",\"status\":\"304\",\"content_size\":\"0\",\"time\":\"1995-08-01T00:00:08.000Z\"}',\n '{\"host\":\"uplherc.upl.com\",\"method\":\"GET\",\"endpoint\":\"/images/MOSAIC-logosmall.gif\",\"protocol\":\"HTTP/1.0\",\"status\":\"304\",\"content_size\":\"0\",\"time\":\"1995-08-01T00:00:08.000Z\"}',\n '{\"host\":\"uplherc.upl.com\",\"method\":\"GET\",\"endpoint\":\"/images/USA-logosmall.gif\",\"protocol\":\"HTTP/1.0\",\"status\":\"304\",\"content_size\":\"0\",\"time\":\"1995-08-01T00:00:08.000Z\"}']","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[187]: ['{\"host\":\"in24.inetnebr.com\",\"method\":\"GET\",\"endpoint\":\"/shuttle/missions/sts-68/news/sts-68-mcc-05.txt\",\"protocol\":\"HTTP/1.0\",\"status\":\"200\",\"content_size\":\"1839\",\"time\":\"1995-08-01T00:00:01.000Z\"}',\n '{\"host\":\"uplherc.upl.com\",\"method\":\"GET\",\"endpoint\":\"/\",\"protocol\":\"HTTP/1.0\",\"status\":\"304\",\"content_size\":\"0\",\"time\":\"1995-08-01T00:00:07.000Z\"}',\n '{\"host\":\"uplherc.upl.com\",\"method\":\"GET\",\"endpoint\":\"/images/ksclogo-medium.gif\",\"protocol\":\"HTTP/1.0\",\"status\":\"304\",\"content_size\":\"0\",\"time\":\"1995-08-01T00:00:08.000Z\"}',\n '{\"host\":\"uplherc.upl.com\",\"method\":\"GET\",\"endpoint\":\"/images/MOSAIC-logosmall.gif\",\"protocol\":\"HTTP/1.0\",\"status\":\"304\",\"content_size\":\"0\",\"time\":\"1995-08-01T00:00:08.000Z\"}',\n '{\"host\":\"uplherc.upl.com\",\"method\":\"GET\",\"endpoint\":\"/images/USA-logosmall.gif\",\"protocol\":\"HTTP/1.0\",\"status\":\"304\",\"content_size\":\"0\",\"time\":\"1995-08-01T00:00:08.000Z\"}']"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["There is a lot more you can do about data storing and loading in terms of data formats and settings. Check out more about these options [__here__](https://spark.apache.org/docs/latest/sql-data-sources-load-save-functions.html)."],"metadata":{"colab_type":"text","id":"P9zYYUIcZjUU","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1f4ada6d-7fc2-4a53-a44f-790b18885a2a"}}},{"cell_type":"markdown","source":["### Congratulations! You have finished the mini-project for this unit!"],"metadata":{"colab_type":"text","id":"lLXpioWzZlug","application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9eefd647-8d11-42cd-be8e-e4424ae1c135"}}}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.6","nbconvert_exporter":"python","file_extension":".py"},"name":"Mini_Project_Data_Wrangling_at_Scale_with_Spark_Solutions_checkpoint","notebookId":3935650049725854,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"application/vnd.databricks.v1+notebook":{"notebookName":"Mini_Project_Data_Wrangling_at_Scale_with_Spark","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3048127638877779},"colab":{"name":"Mini_Project_Data_Wrangling_at_Scale_with_Spark_checkpoint.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}
